{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Jane Street Market Prediction: XGBoost and Hyperparameter Tuning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM47zWNG3NHNRj3dpKQgnNr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdtalley/Data-Science-Portfolio/blob/main/Jane_Street_Market_Prediction_XGBoost_and_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-_Z35-CFlwK"
      },
      "source": [
        "# Jane Street Market Prediction: XGBoost and Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXLkpPw2FDu7"
      },
      "source": [
        "## Using Financial Market Data to Predict Successful Trades\n",
        "\n",
        "Financial market data is a driving force behind the decisions of traders everyday. As data collection and processing capabilites grow, and the amount of electronic trading increases with the usage of free trading apps and mechanical/algorithmic based trading, market data and trading data captured from the markets grows in complexity each day. This allows for development of machine learning models that can predict with some degree of accuracy the decision to make on a trade, to pass or initiate the buy of an asset that will give us a positive return on our trade at a later date.\n",
        "\n",
        "### About Our Data\n",
        "\n",
        "This dataset contains an anonymized set of features, feature_{0...129}, representing real stock market data. Each row in the dataset represents a trading opportunity, for which I will be predicting an action value: 1 to make the trade and 0 to pass on it. Each trade has an associated weight and resp, which together represents a return on the trade. The date column is an integer which represents the day of the trade, while ts_id represents a time ordering. In addition to anonymized feature values, you are provided with metadata about the features in features.csv.\n",
        "\n",
        "In the training set, train.csv, we are provided a resp value, as well as several other resp_{1,2,3,4} values that represent returns over different time horizons. These variables are not included in the test set. Trades with weight = 0 were intentionally included in the dataset for completeness.\n",
        "\n",
        "* train.csv - the training set, contains historical data and returns\n",
        "* features.csv - metadata pertaining to the anonymized features\n",
        "\n",
        "\n",
        "Data is from the Jane Street Market Prediction Dataset, linked here; https://www.kaggle.com/c/jane-street-market-prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0cq-0SMJ8F5"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Tqe3WEtv31"
      },
      "source": [
        "# Importing necessary data visualization and machine learning packages and .csv file into a pandas DataFrame.\r\n",
        "%matplotlib inline\r\n",
        "import time\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from scipy import stats\r\n",
        "from google.colab import drive\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "import plotly as py\r\n",
        "import plotly.graph_objs as go\r\n",
        "import plotly.tools as tls\r\n",
        "from plotly.offline import iplot, init_notebook_mode\r\n",
        "import cufflinks\r\n",
        "import cufflinks as cf\r\n",
        "import plotly.figure_factory as ff\r\n",
        "import os\r\n",
        "import warnings\r\n",
        "\r\n",
        "# Suppress warnings.\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhfbEhhetIQX",
        "outputId": "c968f650-36ae-45c2-cae3-658bcd2f7df6"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v13YQOzuFDs"
      },
      "source": [
        "# Importing pandas DataFrame.\r\n",
        "train = pd.read_csv(\"/content/drive/My Drive/Data/train.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV_SdP-64JZ1",
        "outputId": "f97d45ca-1cf6-47f1-d96e-15d94792098f"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Feb  8 05:38:08 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHccMtMtwG3y",
        "outputId": "24bec44d-3957-4c6b-9bf6-46007a20b457"
      },
      "source": [
        "# Viewing DataFrame column types to make sure data types are correct.\r\n",
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2390491 entries, 0 to 2390490\n",
            "Columns: 138 entries, date to ts_id\n",
            "dtypes: float64(135), int64(3)\n",
            "memory usage: 2.5 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "I4F6AFtKvuHx",
        "outputId": "a34fcf9e-8082-46a3-cb38-93fdf31861aa"
      },
      "source": [
        "# Calling pandas head function to take a glance at our data.\r\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>weight</th>\n",
              "      <th>resp_1</th>\n",
              "      <th>resp_2</th>\n",
              "      <th>resp_3</th>\n",
              "      <th>resp_4</th>\n",
              "      <th>resp</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_91</th>\n",
              "      <th>feature_92</th>\n",
              "      <th>feature_93</th>\n",
              "      <th>feature_94</th>\n",
              "      <th>feature_95</th>\n",
              "      <th>feature_96</th>\n",
              "      <th>feature_97</th>\n",
              "      <th>feature_98</th>\n",
              "      <th>feature_99</th>\n",
              "      <th>feature_100</th>\n",
              "      <th>feature_101</th>\n",
              "      <th>feature_102</th>\n",
              "      <th>feature_103</th>\n",
              "      <th>feature_104</th>\n",
              "      <th>feature_105</th>\n",
              "      <th>feature_106</th>\n",
              "      <th>feature_107</th>\n",
              "      <th>feature_108</th>\n",
              "      <th>feature_109</th>\n",
              "      <th>feature_110</th>\n",
              "      <th>feature_111</th>\n",
              "      <th>feature_112</th>\n",
              "      <th>feature_113</th>\n",
              "      <th>feature_114</th>\n",
              "      <th>feature_115</th>\n",
              "      <th>feature_116</th>\n",
              "      <th>feature_117</th>\n",
              "      <th>feature_118</th>\n",
              "      <th>feature_119</th>\n",
              "      <th>feature_120</th>\n",
              "      <th>feature_121</th>\n",
              "      <th>feature_122</th>\n",
              "      <th>feature_123</th>\n",
              "      <th>feature_124</th>\n",
              "      <th>feature_125</th>\n",
              "      <th>feature_126</th>\n",
              "      <th>feature_127</th>\n",
              "      <th>feature_128</th>\n",
              "      <th>feature_129</th>\n",
              "      <th>ts_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009916</td>\n",
              "      <td>0.014079</td>\n",
              "      <td>0.008773</td>\n",
              "      <td>0.001390</td>\n",
              "      <td>0.006270</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.872746</td>\n",
              "      <td>-2.191242</td>\n",
              "      <td>-0.474163</td>\n",
              "      <td>-0.323046</td>\n",
              "      <td>0.014688</td>\n",
              "      <td>-0.002484</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.989982</td>\n",
              "      <td>-1.055090</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.667671</td>\n",
              "      <td>-2.001475</td>\n",
              "      <td>-1.703595</td>\n",
              "      <td>-2.196892</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.483295</td>\n",
              "      <td>1.307466</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.175200</td>\n",
              "      <td>0.967805</td>\n",
              "      <td>1.608410</td>\n",
              "      <td>1.319365</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.515073</td>\n",
              "      <td>-0.448988</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158770</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.754522</td>\n",
              "      <td>7.137163</td>\n",
              "      <td>-1.863069</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.434466</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.292035</td>\n",
              "      <td>0.317003</td>\n",
              "      <td>-2.605820</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.896986</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.485813</td>\n",
              "      <td>4.147254</td>\n",
              "      <td>-2.238831</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.892724</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.156332</td>\n",
              "      <td>0.622816</td>\n",
              "      <td>-3.921523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.561593</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.457757</td>\n",
              "      <td>6.649580</td>\n",
              "      <td>-1.472686</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.168391</td>\n",
              "      <td>8.313583</td>\n",
              "      <td>1.782433</td>\n",
              "      <td>14.018213</td>\n",
              "      <td>2.653056</td>\n",
              "      <td>12.600292</td>\n",
              "      <td>2.301488</td>\n",
              "      <td>11.445807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>16.673515</td>\n",
              "      <td>-0.002828</td>\n",
              "      <td>-0.003226</td>\n",
              "      <td>-0.007319</td>\n",
              "      <td>-0.011114</td>\n",
              "      <td>-0.009792</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.349537</td>\n",
              "      <td>-1.704709</td>\n",
              "      <td>0.068058</td>\n",
              "      <td>0.028432</td>\n",
              "      <td>0.193794</td>\n",
              "      <td>0.138212</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.151877</td>\n",
              "      <td>-0.384952</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.225838</td>\n",
              "      <td>0.789076</td>\n",
              "      <td>1.110580</td>\n",
              "      <td>1.102281</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.590600</td>\n",
              "      <td>-0.625682</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.543425</td>\n",
              "      <td>-0.547486</td>\n",
              "      <td>-0.706600</td>\n",
              "      <td>-0.667806</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.910558</td>\n",
              "      <td>0.914465</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.157671</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.297679</td>\n",
              "      <td>1.281956</td>\n",
              "      <td>-2.427595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.024913</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.413607</td>\n",
              "      <td>-0.073672</td>\n",
              "      <td>-2.434546</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.949879</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.724655</td>\n",
              "      <td>1.622137</td>\n",
              "      <td>-2.209020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.332492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.586619</td>\n",
              "      <td>-1.040491</td>\n",
              "      <td>-3.946097</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.983440</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.357907</td>\n",
              "      <td>1.612348</td>\n",
              "      <td>-1.664544</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.178850</td>\n",
              "      <td>1.777472</td>\n",
              "      <td>-0.915458</td>\n",
              "      <td>2.831612</td>\n",
              "      <td>-1.417010</td>\n",
              "      <td>2.297459</td>\n",
              "      <td>-1.304614</td>\n",
              "      <td>1.898684</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025134</td>\n",
              "      <td>0.027607</td>\n",
              "      <td>0.033406</td>\n",
              "      <td>0.034380</td>\n",
              "      <td>0.023970</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.812780</td>\n",
              "      <td>-0.256156</td>\n",
              "      <td>0.806463</td>\n",
              "      <td>0.400221</td>\n",
              "      <td>-0.614188</td>\n",
              "      <td>-0.354800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.448261</td>\n",
              "      <td>2.668029</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.836342</td>\n",
              "      <td>2.183258</td>\n",
              "      <td>3.902698</td>\n",
              "      <td>3.045431</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.141082</td>\n",
              "      <td>-0.979962</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.157585</td>\n",
              "      <td>-0.966803</td>\n",
              "      <td>-1.430973</td>\n",
              "      <td>-1.103432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.131559</td>\n",
              "      <td>4.314714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2.420089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.800962</td>\n",
              "      <td>1.143663</td>\n",
              "      <td>-3.214578</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.585939</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.193996</td>\n",
              "      <td>0.953114</td>\n",
              "      <td>-2.674838</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.200085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.537175</td>\n",
              "      <td>2.156228</td>\n",
              "      <td>-3.568648</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.193823</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.097345</td>\n",
              "      <td>0.796214</td>\n",
              "      <td>-4.090058</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.548596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.882588</td>\n",
              "      <td>1.817895</td>\n",
              "      <td>-2.432424</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.115747</td>\n",
              "      <td>9.667908</td>\n",
              "      <td>5.542871</td>\n",
              "      <td>11.671595</td>\n",
              "      <td>7.281757</td>\n",
              "      <td>10.060014</td>\n",
              "      <td>6.638248</td>\n",
              "      <td>9.427299</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.004730</td>\n",
              "      <td>-0.003273</td>\n",
              "      <td>-0.000461</td>\n",
              "      <td>-0.000476</td>\n",
              "      <td>-0.003200</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.174378</td>\n",
              "      <td>0.344640</td>\n",
              "      <td>0.066872</td>\n",
              "      <td>0.009357</td>\n",
              "      <td>-1.006373</td>\n",
              "      <td>-0.676458</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.508206</td>\n",
              "      <td>2.484260</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.902176</td>\n",
              "      <td>1.799163</td>\n",
              "      <td>3.192700</td>\n",
              "      <td>2.848359</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.401637</td>\n",
              "      <td>-1.428248</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.421175</td>\n",
              "      <td>-1.487976</td>\n",
              "      <td>-1.756415</td>\n",
              "      <td>-1.647543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.766182</td>\n",
              "      <td>4.528353</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2.330484</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.182066</td>\n",
              "      <td>1.088451</td>\n",
              "      <td>-3.527752</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.338859</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.257774</td>\n",
              "      <td>-1.194013</td>\n",
              "      <td>-1.719062</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.940190</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.510224</td>\n",
              "      <td>-1.781693</td>\n",
              "      <td>-3.373969</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.513074</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.424964</td>\n",
              "      <td>1.992887</td>\n",
              "      <td>-2.616856</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.561528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.994041</td>\n",
              "      <td>0.099560</td>\n",
              "      <td>-2.485993</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.838853</td>\n",
              "      <td>0.499251</td>\n",
              "      <td>3.033732</td>\n",
              "      <td>1.513488</td>\n",
              "      <td>4.397532</td>\n",
              "      <td>1.266037</td>\n",
              "      <td>3.856384</td>\n",
              "      <td>1.013469</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.138531</td>\n",
              "      <td>0.001252</td>\n",
              "      <td>0.002165</td>\n",
              "      <td>-0.001215</td>\n",
              "      <td>-0.006219</td>\n",
              "      <td>-0.002604</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.172026</td>\n",
              "      <td>-3.093182</td>\n",
              "      <td>-0.161518</td>\n",
              "      <td>-0.128149</td>\n",
              "      <td>-0.195006</td>\n",
              "      <td>-0.143780</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.683018</td>\n",
              "      <td>1.450991</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.257761</td>\n",
              "      <td>0.632336</td>\n",
              "      <td>0.905204</td>\n",
              "      <td>0.575275</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.550883</td>\n",
              "      <td>2.484082</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.502828</td>\n",
              "      <td>2.606440</td>\n",
              "      <td>2.731251</td>\n",
              "      <td>2.566561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.477905</td>\n",
              "      <td>-1.722451</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>4.345282</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.737738</td>\n",
              "      <td>2.602937</td>\n",
              "      <td>-1.785502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.172561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.299516</td>\n",
              "      <td>-0.420021</td>\n",
              "      <td>-2.354611</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.762192</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.598620</td>\n",
              "      <td>0.623132</td>\n",
              "      <td>-1.742540</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.934675</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.373013</td>\n",
              "      <td>-1.213540</td>\n",
              "      <td>-3.677787</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.684119</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.861848</td>\n",
              "      <td>2.134804</td>\n",
              "      <td>-1.279284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.344850</td>\n",
              "      <td>4.101145</td>\n",
              "      <td>0.614252</td>\n",
              "      <td>6.623456</td>\n",
              "      <td>0.800129</td>\n",
              "      <td>5.233243</td>\n",
              "      <td>0.362636</td>\n",
              "      <td>3.926633</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   date     weight    resp_1  ...  feature_128  feature_129  ts_id\n",
              "0     0   0.000000  0.009916  ...     2.301488    11.445807      0\n",
              "1     0  16.673515 -0.002828  ...    -1.304614     1.898684      1\n",
              "2     0   0.000000  0.025134  ...     6.638248     9.427299      2\n",
              "3     0   0.000000 -0.004730  ...     3.856384     1.013469      3\n",
              "4     0   0.138531  0.001252  ...     0.362636     3.926633      4\n",
              "\n",
              "[5 rows x 138 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wQ3GgQfyf0B"
      },
      "source": [
        "# Setting max rows to show all percent missing values.\r\n",
        "pd.set_option(\"max_rows\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fS9QwUEmxDli",
        "outputId": "98604861-ecbf-43dd-bf02-8e428ae9fa32"
      },
      "source": [
        "# Finding the percent of missing values by calling pandas .isna function which returns a mask of bool values for each element in \r\n",
        "# DataFrame that indicates whether an element is not an NA value, and rounding the mean.\r\n",
        "percent_missing = train.isna().mean().round(4) * 100\r\n",
        "percent_missing = pd.DataFrame(percent_missing)\r\n",
        "percent_missing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>resp_1</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>resp_2</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>resp_3</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>resp_4</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>resp</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_0</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_6</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_7</th>\n",
              "      <td>16.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_8</th>\n",
              "      <td>16.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_9</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_10</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_11</th>\n",
              "      <td>3.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_12</th>\n",
              "      <td>3.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_13</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_14</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_15</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_16</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_17</th>\n",
              "      <td>16.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_18</th>\n",
              "      <td>16.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_19</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_20</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_21</th>\n",
              "      <td>3.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_22</th>\n",
              "      <td>3.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_23</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_24</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_25</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_26</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_27</th>\n",
              "      <td>16.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_28</th>\n",
              "      <td>16.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_29</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_30</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_31</th>\n",
              "      <td>3.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_32</th>\n",
              "      <td>3.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_33</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_34</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_35</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_36</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_37</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_38</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_39</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_40</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_41</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_42</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_43</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_44</th>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_45</th>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_46</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_47</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_48</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_49</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_50</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_51</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_52</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_53</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_54</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_55</th>\n",
              "      <td>2.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_56</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_57</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_58</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_59</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_60</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_61</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_62</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_63</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_64</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_65</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_66</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_67</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_68</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_69</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_70</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_71</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_72</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_73</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_74</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_75</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_76</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_77</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_78</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_79</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_80</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_81</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_82</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_83</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_84</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_85</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_86</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_87</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_88</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_89</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_90</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_91</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_92</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_93</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_94</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_95</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_96</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_97</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_98</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_99</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_100</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_101</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_102</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_103</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_104</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_105</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_106</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_107</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_108</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_109</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_110</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_111</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_112</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_113</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_114</th>\n",
              "      <td>14.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_115</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_116</th>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_117</th>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_118</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_119</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_120</th>\n",
              "      <td>2.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_121</th>\n",
              "      <td>2.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_122</th>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_123</th>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_124</th>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_125</th>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_126</th>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_127</th>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_128</th>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_129</th>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ts_id</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "date          0.00\n",
              "weight        0.00\n",
              "resp_1        0.00\n",
              "resp_2        0.00\n",
              "resp_3        0.00\n",
              "resp_4        0.00\n",
              "resp          0.00\n",
              "feature_0     0.00\n",
              "feature_1     0.00\n",
              "feature_2     0.00\n",
              "feature_3     0.02\n",
              "feature_4     0.02\n",
              "feature_5     0.00\n",
              "feature_6     0.00\n",
              "feature_7    16.45\n",
              "feature_8    16.45\n",
              "feature_9     0.03\n",
              "feature_10    0.03\n",
              "feature_11    3.35\n",
              "feature_12    3.35\n",
              "feature_13    0.64\n",
              "feature_14    0.64\n",
              "feature_15    0.28\n",
              "feature_16    0.28\n",
              "feature_17   16.55\n",
              "feature_18   16.55\n",
              "feature_19    0.03\n",
              "feature_20    0.03\n",
              "feature_21    3.41\n",
              "feature_22    3.41\n",
              "feature_23    0.64\n",
              "feature_24    0.64\n",
              "feature_25    0.28\n",
              "feature_26    0.28\n",
              "feature_27   16.55\n",
              "feature_28   16.55\n",
              "feature_29    0.03\n",
              "feature_30    0.03\n",
              "feature_31    3.41\n",
              "feature_32    3.41\n",
              "feature_33    0.64\n",
              "feature_34    0.64\n",
              "feature_35    0.28\n",
              "feature_36    0.28\n",
              "feature_37    0.00\n",
              "feature_38    0.00\n",
              "feature_39    0.00\n",
              "feature_40    0.00\n",
              "feature_41    0.00\n",
              "feature_42    0.00\n",
              "feature_43    0.00\n",
              "feature_44    0.02\n",
              "feature_45    0.02\n",
              "feature_46    0.00\n",
              "feature_47    0.00\n",
              "feature_48    0.00\n",
              "feature_49    0.00\n",
              "feature_50    0.00\n",
              "feature_51    0.00\n",
              "feature_52    0.00\n",
              "feature_53    0.00\n",
              "feature_54    0.00\n",
              "feature_55    2.86\n",
              "feature_56    0.03\n",
              "feature_57    0.00\n",
              "feature_58    0.00\n",
              "feature_59    0.00\n",
              "feature_60    0.00\n",
              "feature_61    0.00\n",
              "feature_62    0.00\n",
              "feature_63    0.00\n",
              "feature_64    0.00\n",
              "feature_65    0.00\n",
              "feature_66    0.00\n",
              "feature_67    0.00\n",
              "feature_68    0.00\n",
              "feature_69    0.00\n",
              "feature_70    0.00\n",
              "feature_71    0.00\n",
              "feature_72   14.70\n",
              "feature_73    0.03\n",
              "feature_74    2.68\n",
              "feature_75    0.64\n",
              "feature_76    0.28\n",
              "feature_77    0.00\n",
              "feature_78   14.70\n",
              "feature_79    0.03\n",
              "feature_80    2.68\n",
              "feature_81    0.64\n",
              "feature_82    0.28\n",
              "feature_83    0.00\n",
              "feature_84   14.70\n",
              "feature_85    0.03\n",
              "feature_86    2.68\n",
              "feature_87    0.64\n",
              "feature_88    0.28\n",
              "feature_89    0.00\n",
              "feature_90   14.70\n",
              "feature_91    0.03\n",
              "feature_92    2.68\n",
              "feature_93    0.64\n",
              "feature_94    0.28\n",
              "feature_95    0.00\n",
              "feature_96   14.70\n",
              "feature_97    0.03\n",
              "feature_98    2.68\n",
              "feature_99    0.64\n",
              "feature_100   0.28\n",
              "feature_101   0.00\n",
              "feature_102  14.70\n",
              "feature_103   0.03\n",
              "feature_104   2.68\n",
              "feature_105   0.64\n",
              "feature_106   0.28\n",
              "feature_107   0.00\n",
              "feature_108  14.70\n",
              "feature_109   0.03\n",
              "feature_110   2.68\n",
              "feature_111   0.64\n",
              "feature_112   0.28\n",
              "feature_113   0.00\n",
              "feature_114  14.70\n",
              "feature_115   0.03\n",
              "feature_116   2.68\n",
              "feature_117   0.64\n",
              "feature_118   0.28\n",
              "feature_119   0.00\n",
              "feature_120   2.92\n",
              "feature_121   2.92\n",
              "feature_122   0.01\n",
              "feature_123   0.01\n",
              "feature_124   0.67\n",
              "feature_125   0.67\n",
              "feature_126   0.37\n",
              "feature_127   0.37\n",
              "feature_128   0.08\n",
              "feature_129   0.08\n",
              "ts_id         0.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMUtHgQAy40Z"
      },
      "source": [
        "Some of our features are missing a good amount of data, but this is still an acceptable amount. We can proceed further with machine learning analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7S3s6vcvvQR"
      },
      "source": [
        "# Importing pandas DataFrame.\r\n",
        "features =  pd.read_csv(\"/content/drive/My Drive/Data/features.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72DpyqFYwJvb",
        "outputId": "b0561b19-a9ff-4cbc-ccd0-6b46eeac009e"
      },
      "source": [
        "# Viewing DataFrame column types to make sure data types are correct.\r\n",
        "features.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 130 entries, 0 to 129\n",
            "Data columns (total 30 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   feature  130 non-null    object\n",
            " 1   tag_0    130 non-null    bool  \n",
            " 2   tag_1    130 non-null    bool  \n",
            " 3   tag_2    130 non-null    bool  \n",
            " 4   tag_3    130 non-null    bool  \n",
            " 5   tag_4    130 non-null    bool  \n",
            " 6   tag_5    130 non-null    bool  \n",
            " 7   tag_6    130 non-null    bool  \n",
            " 8   tag_7    130 non-null    bool  \n",
            " 9   tag_8    130 non-null    bool  \n",
            " 10  tag_9    130 non-null    bool  \n",
            " 11  tag_10   130 non-null    bool  \n",
            " 12  tag_11   130 non-null    bool  \n",
            " 13  tag_12   130 non-null    bool  \n",
            " 14  tag_13   130 non-null    bool  \n",
            " 15  tag_14   130 non-null    bool  \n",
            " 16  tag_15   130 non-null    bool  \n",
            " 17  tag_16   130 non-null    bool  \n",
            " 18  tag_17   130 non-null    bool  \n",
            " 19  tag_18   130 non-null    bool  \n",
            " 20  tag_19   130 non-null    bool  \n",
            " 21  tag_20   130 non-null    bool  \n",
            " 22  tag_21   130 non-null    bool  \n",
            " 23  tag_22   130 non-null    bool  \n",
            " 24  tag_23   130 non-null    bool  \n",
            " 25  tag_24   130 non-null    bool  \n",
            " 26  tag_25   130 non-null    bool  \n",
            " 27  tag_26   130 non-null    bool  \n",
            " 28  tag_27   130 non-null    bool  \n",
            " 29  tag_28   130 non-null    bool  \n",
            "dtypes: bool(29), object(1)\n",
            "memory usage: 4.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "4gMDTU67v4Bt",
        "outputId": "95739471-bb60-4c89-d33d-c787790af2fe"
      },
      "source": [
        "# Calling pandas head function to take a glance at our data.\r\n",
        "features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>tag_0</th>\n",
              "      <th>tag_1</th>\n",
              "      <th>tag_2</th>\n",
              "      <th>tag_3</th>\n",
              "      <th>tag_4</th>\n",
              "      <th>tag_5</th>\n",
              "      <th>tag_6</th>\n",
              "      <th>tag_7</th>\n",
              "      <th>tag_8</th>\n",
              "      <th>tag_9</th>\n",
              "      <th>tag_10</th>\n",
              "      <th>tag_11</th>\n",
              "      <th>tag_12</th>\n",
              "      <th>tag_13</th>\n",
              "      <th>tag_14</th>\n",
              "      <th>tag_15</th>\n",
              "      <th>tag_16</th>\n",
              "      <th>tag_17</th>\n",
              "      <th>tag_18</th>\n",
              "      <th>tag_19</th>\n",
              "      <th>tag_20</th>\n",
              "      <th>tag_21</th>\n",
              "      <th>tag_22</th>\n",
              "      <th>tag_23</th>\n",
              "      <th>tag_24</th>\n",
              "      <th>tag_25</th>\n",
              "      <th>tag_26</th>\n",
              "      <th>tag_27</th>\n",
              "      <th>tag_28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>feature_0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>feature_1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>feature_2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>feature_3</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>feature_4</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature  tag_0  tag_1  tag_2  ...  tag_25  tag_26  tag_27  tag_28\n",
              "0  feature_0  False  False  False  ...   False   False   False   False\n",
              "1  feature_1  False  False  False  ...   False   False   False   False\n",
              "2  feature_2  False  False  False  ...   False   False   False   False\n",
              "3  feature_3  False  False  False  ...   False   False   False   False\n",
              "4  feature_4  False  False  False  ...   False   False   False   False\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo6Ph-e32bXm"
      },
      "source": [
        "# Target Variable and Train-Test-Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCNantckv5Dc"
      },
      "source": [
        "# Disregarding trades that do not contribute to scoring with a weight of 0 for training set.\r\n",
        "train = train[train['weight'] != 0]\r\n",
        "# Creating query to train data on certain date range of 85 days.\r\n",
        "train = train.query('date > 85').reset_index(drop = True) \r\n",
        "# Limiting memory usage by converting float 64 to float 32 in applicable data types.\r\n",
        "train = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\r\n",
        "\r\n",
        "# Creating target variable by multiplying weight and resp values and selecting those with a positive return.\r\n",
        "train['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\r\n",
        "\r\n",
        "# Filling missing values with the mean.\r\n",
        "train.fillna(train.mean(),inplace=True)\r\n",
        "\r\n",
        "cols = [c for c in train.columns if 'feature' in c]\r\n",
        "\r\n",
        "# Creating independent variables by extracting feature columns to create X variable.\r\n",
        "X = train.loc[:, train.columns.str.contains('feature')]\r\n",
        "# Creating our target variable using our newly created action variable.\r\n",
        "Y = train.loc[:, 'action']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "U6GpzzoN2wMl",
        "outputId": "c201ee38-56bc-4fa8-a6f1-dae59bdf706b"
      },
      "source": [
        "# Creating a simple plot to show class balance.\r\n",
        "x = train['action'].value_counts().index\r\n",
        "y = train['action'].value_counts().values\r\n",
        "\r\n",
        "trace2 = go.Bar(\r\n",
        "     x=x ,\r\n",
        "     y=y,\r\n",
        "     marker=dict(\r\n",
        "         color=y,\r\n",
        "         colorscale = 'Viridis',\r\n",
        "         reversescale = True\r\n",
        "     ),\r\n",
        "     name=\"Imbalance\",    \r\n",
        " )\r\n",
        "layout = dict(\r\n",
        "     title=\"Class Balance for Target Variable\",\r\n",
        "     #width = 900, height = 500,\r\n",
        "     xaxis=go.layout.XAxis(\r\n",
        "     automargin=True),\r\n",
        "     yaxis=dict(\r\n",
        "         showgrid=False,\r\n",
        "         showline=False,\r\n",
        "         showticklabels=True,\r\n",
        " #         domain=[0, 0.85],\r\n",
        "     ), \r\n",
        ")\r\n",
        "fig1 = go.Figure(data=[trace2], layout=layout)\r\n",
        "iplot(fig1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"01f2b897-46e3-4e1c-b14f-2655898d8f40\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"01f2b897-46e3-4e1c-b14f-2655898d8f40\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '01f2b897-46e3-4e1c-b14f-2655898d8f40',\n",
              "                        [{\"marker\": {\"color\": [789325, 782090], \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"reversescale\": true}, \"name\": \"Imbalance\", \"type\": \"bar\", \"x\": [1, 0], \"y\": [789325, 782090]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Class Balance for Target Variable\"}, \"xaxis\": {\"automargin\": true}, \"yaxis\": {\"showgrid\": false, \"showline\": false, \"showticklabels\": true}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('01f2b897-46e3-4e1c-b14f-2655898d8f40');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWP7lkXGWWhb"
      },
      "source": [
        "The target variable is balanced and does not need any further processing to fix class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfnKO_ILJK0K"
      },
      "source": [
        "# Using sklearns train_test_split to split data into random train and test subsets to calculate accuracy.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrI0_JnUXdW7"
      },
      "source": [
        "# XGBoost Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUTTsV4zXjKN"
      },
      "source": [
        "First we will set up a simple XGBoost classification model without hyperparameter tuning to see how performance is increased with RandomSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoRywPLmzwbT",
        "outputId": "4c3b2b20-c100-4ad7-a7a3-e0f3f8ff7b2e"
      },
      "source": [
        "import xgboost as xgb\r\n",
        "print(\"XGBoost version:\", xgb.__version__)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBoost version: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aigq8wD3b_y"
      },
      "source": [
        "clf = xgb.XGBClassifier(\r\n",
        "    random_state=2021,\r\n",
        "    tree_method='gpu_hist'  # Needed for GPU usage.\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESjf6T0H3e-p",
        "outputId": "b383819d-d609-4e65-815d-f4a7206ee446"
      },
      "source": [
        "%time clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.49 s, sys: 1.53 s, total: 5.02 s\n",
            "Wall time: 5.41 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=2021,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, tree_method='gpu_hist', verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jjpl_E7HxYi",
        "outputId": "82e1cfa5-b4e1-44b4-9db1-f9aa5b566718"
      },
      "source": [
        "# Print classification report for our XGBoost classifier.\r\n",
        "y_pred = clf.predict(X_test)\r\n",
        "accuracy = accuracy_score(y_test,y_pred)\r\n",
        "report = classification_report(y_test, y_pred)\r\n",
        "cm = confusion_matrix(y_test, y_pred)\r\n",
        "\r\n",
        "print(\"Accuracy: \", accuracy)\r\n",
        "print(\"Classification report:\")\r\n",
        "print(report)\r\n",
        "print(\"Confusion matrix:\")\r\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5278141038490787\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.48      0.50    156239\n",
            "           1       0.53      0.57      0.55    158044\n",
            "\n",
            "    accuracy                           0.53    314283\n",
            "   macro avg       0.53      0.53      0.53    314283\n",
            "weighted avg       0.53      0.53      0.53    314283\n",
            "\n",
            "Confusion matrix:\n",
            "[[75013 81226]\n",
            " [67174 90870]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-XKHO4lDtJd",
        "outputId": "1d344255-ac0a-49c4-a690-fbb59a4fa48a"
      },
      "source": [
        "# Print cross validation score.\r\n",
        "cross_val_score(clf, X_train, y_train, cv=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5290124 , 0.52668568, 0.52656448, 0.52629402, 0.52789688])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRbffm14Xuhr"
      },
      "source": [
        "Model performance metrics leave much more to be desired. We will adjust hyperparameters with further models to demonstrate the importance of hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFBnv_I4bqKt"
      },
      "source": [
        "# XGBoost: Hyperparameter Tuning Using RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aDyAZsJncCEI",
        "outputId": "3c4c61eb-41e4-498c-bad1-eac82d442d73"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create parameter grid for RandomizedSearchCV.\n",
        "parameters = {'n_estimators':[1000,2000],\n",
        "              'max_depth':[12,22],\n",
        "              'learning_rate':[0.03,0.06],\n",
        "              'subsample':[0.5,1],\n",
        "              'colsample_bytree':[1,0.5],\n",
        "              'gamma':[0.5,1],\n",
        "              'min_child_weight':[1,2],\n",
        "              'tree_method':['gpu_hist']}\n",
        "\n",
        "# Create decision tree classifier with RandomizedSearchCV.\n",
        "CV_clf = RandomizedSearchCV(clf, parameters, random_state=0)\n",
        "\n",
        "# Fitting decision tree classifier to training data.\n",
        "CV_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=None, error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=1, gamma=0,\n",
              "                                           learning_rate=0.1, max_delta_step=0,\n",
              "                                           max_depth=3, min_child_weight=1,\n",
              "                                           missing=None, n_estimators=100,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='binary:logistic',\n",
              "                                           random_state=2021, reg_alpha=0,\n",
              "                                           reg_lambd...\n",
              "                                           verbosity=1),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'colsample_bytree': [1, 0.5],\n",
              "                                        'gamma': [0.5, 1],\n",
              "                                        'learning_rate': [0.03, 0.06],\n",
              "                                        'max_depth': [6, 12],\n",
              "                                        'min_child_weight': [1, 2],\n",
              "                                        'n_estimators': [500, 1000],\n",
              "                                        'subsample': [0.5, 1],\n",
              "                                        'tree_method': ['gpu_hist']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RWHcwkikjOg",
        "outputId": "17303ce1-7e33-4566-d9a3-946b93ea59a3"
      },
      "source": [
        "# Calling .best_params_ to pull best parameters from RandomizedSearchCV.\n",
        "CV_clf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.5,\n",
              " 'gamma': 1,\n",
              " 'learning_rate': 0.06,\n",
              " 'max_depth': 12,\n",
              " 'min_child_weight': 2,\n",
              " 'n_estimators': 1000,\n",
              " 'subsample': 1,\n",
              " 'tree_method': 'gpu_hist'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBjP4lmW1jIz"
      },
      "source": [
        "clf = xgb.XGBClassifier(\n",
        "    random_state=0,\n",
        "    tree_method='gpu_hist',  # Needed for GPU usage.\n",
        "    colsample_bytree=0.5,\n",
        "    gamma=1,\n",
        "    learning_rate=0.06,\n",
        "    max_depth=12,\n",
        "    min_child_weight=2,\n",
        "    n_estimators=1000,\n",
        "    subsample=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6j7IuBp2vGD",
        "outputId": "5bc2d233-5f54-4b6a-8cf0-e6b62071553a"
      },
      "source": [
        "%time clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 19s, sys: 13 s, total: 1min 32s\n",
            "Wall time: 1min 32s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=0.5, gamma=1,\n",
              "              learning_rate=0.06, max_delta_step=0, max_depth=12,\n",
              "              min_child_weight=2, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, tree_method='gpu_hist', verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzM2mNMv2x9S",
        "outputId": "caca331c-2628-4851-f3e6-c867d27b872b"
      },
      "source": [
        "# Print classification report for our XGBoost classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6407378063719641\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.63      0.64    156239\n",
            "           1       0.64      0.65      0.64    158044\n",
            "\n",
            "    accuracy                           0.64    314283\n",
            "   macro avg       0.64      0.64      0.64    314283\n",
            "weighted avg       0.64      0.64      0.64    314283\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 98847  57392]\n",
            " [ 55518 102526]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McbCjyJK20B_",
        "outputId": "21d2675b-ecb7-412e-bf49-6700a07ad714"
      },
      "source": [
        "# Print cross validation score.\n",
        "cross_val_score(clf, X_train, y_train, cv=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.62702892, 0.62617778, 0.6226325 , 0.6273138 , 0.62595356])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYX_iqrkYEzY"
      },
      "source": [
        "We were able to increase model performance by 10%, a major increase. This makes our model certainly more viable, but we need to adjust it further with another hyperparameter grid exploring larger numbers of estimators and max_depth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PDRjtP4z3lF-",
        "outputId": "a38256fd-7333-4769-be48-0be2bd5f9a7b"
      },
      "source": [
        "# Creating another parameter grid for RandomizedSearchCV.\n",
        "parameters = {'n_estimators':[1000,2000],\n",
        "              'max_depth':[12,24],\n",
        "              'learning_rate':[0.06,0.2],\n",
        "              'subsample':[1],\n",
        "              'colsample_bytree':[0.5],\n",
        "              'gamma':[0.5,1],\n",
        "              'min_child_weight':[2,4],\n",
        "              'tree_method':['gpu_hist']}\n",
        "\n",
        "# Create decision tree classifier with RandomizedSearchCV.\n",
        "CV_clf = RandomizedSearchCV(clf, parameters, random_state=0)\n",
        "\n",
        "# Fitting decision tree classifier to training data.\n",
        "CV_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=None, error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=0.5, gamma=1,\n",
              "                                           learning_rate=0.06, max_delta_step=0,\n",
              "                                           max_depth=12, min_child_weight=2,\n",
              "                                           missing=None, n_estimators=1000,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='binary:logistic',\n",
              "                                           random_state=0, reg_alpha=0,\n",
              "                                           reg_lam...\n",
              "                                           verbosity=1),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'colsample_bytree': [0.5],\n",
              "                                        'gamma': [0.5, 1],\n",
              "                                        'learning_rate': [0.06, 0.2],\n",
              "                                        'max_depth': [12, 24],\n",
              "                                        'min_child_weight': [2, 4],\n",
              "                                        'n_estimators': [1000, 2000],\n",
              "                                        'subsample': [1],\n",
              "                                        'tree_method': ['gpu_hist']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuhanuQY5JLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67646805-8cbc-4408-b174-ed0e98aa5ebd"
      },
      "source": [
        "# Calling .best_params_ to pull best parameters from RandomizedSearchCV.\n",
        "CV_clf.best_params_"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.5,\n",
              " 'gamma': 1,\n",
              " 'learning_rate': 0.06,\n",
              " 'max_depth': 24,\n",
              " 'min_child_weight': 2,\n",
              " 'n_estimators': 1000,\n",
              " 'subsample': 1,\n",
              " 'tree_method': 'gpu_hist'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuWQEcYFEnUc"
      },
      "source": [
        "clf = xgb.XGBClassifier(\n",
        "    random_state=0,\n",
        "    tree_method='gpu_hist',  # Needed for GPU usage.\n",
        "    colsample_bytree=0.5,\n",
        "    gamma=1,\n",
        "    learning_rate=0.06,\n",
        "    max_depth=24,\n",
        "    min_child_weight=2,\n",
        "    n_estimators=1000,\n",
        "    subsample=1,\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aUtVvmAEqUE",
        "outputId": "8d49733c-4ace-40a0-d93d-94da2766ac11"
      },
      "source": [
        "%time clf.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13min 2s, sys: 1min, total: 14min 3s\n",
            "Wall time: 14min 2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=0.5, gamma=1,\n",
              "              learning_rate=0.06, max_delta_step=0, max_depth=24,\n",
              "              min_child_weight=2, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, tree_method='gpu_hist', verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfulImLFEsgA",
        "outputId": "ae169a38-4e26-487d-d931-dde4245d3383"
      },
      "source": [
        "# Print classification report for our XGBoost classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6748949195470324\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.67      0.67    156239\n",
            "           1       0.67      0.68      0.68    158044\n",
            "\n",
            "    accuracy                           0.67    314283\n",
            "   macro avg       0.67      0.67      0.67    314283\n",
            "weighted avg       0.67      0.67      0.67    314283\n",
            "\n",
            "Confusion matrix:\n",
            "[[103972  52267]\n",
            " [ 49908 108136]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS1yckVfIX13"
      },
      "source": [
        "We can see that increasing our XGBoost models max_depth increases performance slightly again with a model performance increase in accuracy scoring of about 5%. Further testing with increased max_depth up to 100 did not show any signs of model improvement, only longer run times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WT4E-9Ban0N"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s9R6X5GaqLz"
      },
      "source": [
        "This notebook demonstrates the importance of hyperparameter tuning when it comes to model performance. Our initial model was not showing any useful predictive accuracy, with a scoring of 52%. After hyperparameter tuning we were able to achieve a predictive accuracy of almost 68%, a roughly 16% increase in model accuracy scoring. XGBoost continues to be a useful model for working with large amounts of complex numerical data like the market data here."
      ]
    }
  ]
}