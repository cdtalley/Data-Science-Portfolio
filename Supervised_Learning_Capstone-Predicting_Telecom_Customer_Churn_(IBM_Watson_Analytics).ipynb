{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvZ5XaDJIWzg"
      },
      "source": [
        "# Introduction: Telecom Churn Dataset (IBM Watson Analytics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlnprX56Idwb"
      },
      "source": [
        "Customer churn, also known as customer attrition or customer turnover, is the loss of a client or customer. Customer churn is a key business metric for many different industries; in this case telecommunications technologies. Predicting customer churn has many advantages in solidfying and maximizing customer base. This is because holding onto an existing long-term client is less costly than acquring a new client. Our predictive model could then be used to better help the customer service department select which clients are at greater risk of attrition and respond accordingly to reduce the risk of losing valued clientele.\n",
        "\n",
        "The Telecom Churn Dataset from IBM Watson Analytics is comprised of customer data and customer attrition status gained from IBM customers. Customers who have stopped doing business with IBM are listed in our target variable 'Churn' and assigned a 'Yes' value indicating customer attrition. Our goal is to create a machine learning model that will predict the target variable customer churn and test which machine learning model performs best with our data using various classification metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "bCa7zckipQ4z",
        "outputId": "fa41838b-a5d2-4a8e-f9df-0e3e943bb0ab"
      },
      "outputs": [],
      "source": [
        "from portfolio_utils import set_seed\n",
        "set_seed(42)\n",
        "\n",
        "# Import necessary packages.\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import io\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings.\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data loaded in next cell via portfolio_utils or Colab upload.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "TpLZTWKNqOux",
        "outputId": "7b7f0cfd-9499-4b51-bcd6-ee58424c5505"
      },
      "outputs": [],
      "source": [
        "# Load data: run setup_data.py once, or set DATA_DIR\n",
        "try:\n",
        "    from portfolio_utils.data_loader import load_telecom_churn\n",
        "    df = load_telecom_churn()\n",
        "except Exception:\n",
        "    import os\n",
        "    from pathlib import Path\n",
        "    path = Path(os.environ.get(\"DATA_DIR\", \"data\")) / \"telecom_churn\"\n",
        "    csvs = list(path.rglob(\"*.csv\")) if path.exists() else []\n",
        "    if csvs:\n",
        "        df = pd.read_csv(csvs[0])\n",
        "    else:\n",
        "        import io\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        key = [k for k in uploaded if k.endswith(('.xlsx','.xls','.csv'))][0]\n",
        "        if key.endswith('.csv'):\n",
        "            df = pd.read_csv(io.BytesIO(uploaded[key]))\n",
        "        else:\n",
        "            df = pd.read_excel(io.BytesIO(uploaded[key]))\n",
        "print(f\"Loaded shape: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__IAVBnllGu3"
      },
      "source": [
        "We have now stored our data in a Pandas DataFrame for further analysis. We can get a feel for the dataset before processing by taking a look at the features above. Some features will need to be cleaned as they do not contribute to our data like individual customer ID contained in the customerID feature. Other features will need to be converted from categorical inputs to numerical inputs for machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs275zB7uEOf"
      },
      "source": [
        "# Exploratory Data Analysis and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKMlMZO3mEZ_",
        "outputId": "24d2f66b-023a-4604-9b96-de399df2fdbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customerID        7043 non-null   object \n",
            " 1   gender            7043 non-null   object \n",
            " 2   SeniorCitizen     7043 non-null   int64  \n",
            " 3   Partner           7043 non-null   object \n",
            " 4   Dependents        7043 non-null   object \n",
            " 5   tenure            7043 non-null   int64  \n",
            " 6   PhoneService      7043 non-null   object \n",
            " 7   MultipleLines     7043 non-null   object \n",
            " 8   InternetService   7043 non-null   object \n",
            " 9   OnlineSecurity    7043 non-null   object \n",
            " 10  OnlineBackup      7043 non-null   object \n",
            " 11  DeviceProtection  7043 non-null   object \n",
            " 12  TechSupport       7043 non-null   object \n",
            " 13  StreamingTV       7043 non-null   object \n",
            " 14  StreamingMovies   7043 non-null   object \n",
            " 15  Contract          7043 non-null   object \n",
            " 16  PaperlessBilling  7043 non-null   object \n",
            " 17  PaymentMethod     7043 non-null   object \n",
            " 18  MonthlyCharges    7043 non-null   float64\n",
            " 19  TotalCharges      7043 non-null   object \n",
            " 20  Churn             7043 non-null   object \n",
            "dtypes: float64(1), int64(2), object(18)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# Looking at our DataFrames info we see a majority of our data type is categorical, with a few integer and float columns.\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g-xsLnpd0r_",
        "outputId": "10427bf2-9db9-4265-d1b8-11b6b4b825da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "customerID          0.0\n",
              "gender              0.0\n",
              "SeniorCitizen       0.0\n",
              "Partner             0.0\n",
              "Dependents          0.0\n",
              "tenure              0.0\n",
              "PhoneService        0.0\n",
              "MultipleLines       0.0\n",
              "InternetService     0.0\n",
              "OnlineSecurity      0.0\n",
              "OnlineBackup        0.0\n",
              "DeviceProtection    0.0\n",
              "TechSupport         0.0\n",
              "StreamingTV         0.0\n",
              "StreamingMovies     0.0\n",
              "Contract            0.0\n",
              "PaperlessBilling    0.0\n",
              "PaymentMethod       0.0\n",
              "MonthlyCharges      0.0\n",
              "TotalCharges        0.0\n",
              "Churn               0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We have no missing values which makes our data a little easier to work with.\n",
        "df.isnull().mean() * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pNNRHvIW0rEo"
      },
      "outputs": [],
      "source": [
        "# We can drop our customer ID column as it is not relevant to our target variable. TotalCharges will also be dropped as it only consists of a few values.\n",
        "df = df.drop(columns = ['customerID', 'TotalCharges'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ul-kjKEkx7uN",
        "outputId": "f85072b9-0260-4d60-bae1-151b77d88997"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4de25f2e8>"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting a countplot of our target variable, customer churn using Seaborn.\n",
        "# We can see some class imbalance occuring with our non-attrited customer base outnumbering our attrited customer base.\n",
        "sns.countplot(x ='Churn', data = df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3nBv2H-Svx4Y",
        "outputId": "a1e34475-cf16-4790-b59b-e15d89e1000e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting a correlation heatmap to give us a visual representation of our correlation matrix. \n",
        "plt.figure(figsize=(12, 6))\n",
        "corr = df.apply(lambda x: pd.factorize(x)[0]).corr()\n",
        "ax = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, \n",
        "                 linewidths=.2, cmap=\"YlGnBu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUfUMkFE059a"
      },
      "source": [
        "We can see some features of interest showing a higher correlation value like 'SeniorCitizen' and 'MultipleLines' in regards to our target variable 'Churn' on the far-right column and bottom row. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IInt0GRnVFLM"
      },
      "source": [
        "### Outlier Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kvgl-Py8l5Q"
      },
      "source": [
        "Visually analyzing continuous variables for any outliers that may affect our prediction with a boxplot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OBxbCZ84wdql",
        "outputId": "6bbba5bb-0172-4da7-f074-94a0fc663415"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7fc4de017048>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7fc4de017a58>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc4de017dd8>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7fc4ddfed518>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7fc4ddfed198>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7fc4de017358>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc4de0176d8>]}"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Using pyplot to generate a simple boxplot of our continuous variable 'tenure'.\n",
        "plt.boxplot(df[\"tenure\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGlw4AeTVL2z"
      },
      "source": [
        "Tenure has no visible outliers as seen on the boxplot. These would have been visible as dots along the outer whiskers of the boxplot if there were outliers detected outside of the interquartile range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fbSe5LZCwppN",
        "outputId": "21c3db2e-3f14-424a-a470-d47baa10030f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7fc4dcd73a20>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7fc4dcd80470>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc4dcd807f0>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7fc4dcd80ef0>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7fc4dcd80b70>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7fc4dcd73d30>,\n",
              "  <matplotlib.lines.Line2D at 0x7fc4dcd800f0>]}"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Using pyplot to generate a simple boxplot of our continuous variable 'MonthlyCharges'.\n",
        "plt.boxplot(df[\"MonthlyCharges\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWM7N-NK84ld"
      },
      "source": [
        "The MonthlyCharges feature is also not showing any signs of outliers visually as there are no data points being generated outside of our boxplot's whiskers. We will next confirm this statistically with NumPy's percentile function to generate an interquartile range and test accordingly for any values that are outside of our IQR. It is best practice to confirm any visual clues with a statistical test instead of making assumptions based on visuals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QlzruXSw8J-",
        "outputId": "ce64f669-3878-406c-eb0a-bc3413bf6fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The score threshold is: 1.0\n",
            "Number of outliers is: 0\n",
            "The score threshold is: 1.5\n",
            "Number of outliers is: 0\n",
            "The score threshold is: 2.0\n",
            "Number of outliers is: 0\n",
            "The score threshold is: 2.5\n",
            "Number of outliers is: 0\n",
            "The score threshold is: 3.0\n",
            "Number of outliers is: 0\n",
            "The score threshold is: 3.5\n",
            "Number of outliers is: 0\n",
            "The score threshold is: 4.0\n",
            "Number of outliers is: 0\n",
            "The score threshold is: 4.5\n",
            "Number of outliers is: 0\n"
          ]
        }
      ],
      "source": [
        "# Calculating the IQR using NumPy's percentile function, which returns the q-th percentile(s) of the array elements.\n",
        "q75, q25 = np.percentile(df[\"MonthlyCharges\"], [75 ,25])\n",
        "iqr = q75 - q25\n",
        "\n",
        "# Creating a range of threshold values to test using NumPy in intervals of 0.5.\n",
        "for threshold in np.arange(1,5,0.5):\n",
        "# Creating minimum outlier threshold value.\n",
        "    min_val = q25 - (iqr*threshold)\n",
        "# Creating maximum outlier threshold value.\n",
        "    max_val = q75 + (iqr*threshold)\n",
        "# Printing score threshold and resulting number of outliers detected.\n",
        "    print(\"The score threshold is: {}\".format(threshold))\n",
        "    print(\"Number of outliers is: {}\".format(\n",
        "        len((np.where((df[\"MonthlyCharges\"] > max_val) \n",
        "                      | (df[\"MonthlyCharges\"] < min_val))[0]))\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgXhQBmU9SiT"
      },
      "source": [
        "We found no outliers using various outlier thresholds and IQR to establish  thresholds statistically. The IQR is calculated as the difference between the 75th and the 25th percentiles of the data and defines the box in a box and whisker plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtDVBYQkpzDD"
      },
      "source": [
        "# Class Balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF8sN6oNp5iB"
      },
      "source": [
        "The target variable Churn consists of more data for non-churned employees and is therefore class imbalanced. While this may be good for our organizations performance, it is not going to help our machine learning models perform any better. This will effect our model outcome and create bias towards the highest numbered class, which in this case is our non-attrited customer base. We will apply SMOTE (Synthetic Minority Over-sampling Technique) to increase our minority class synthetically before splitting our data since we do not have enough data to perform undersampling techniques in this situation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJOpe607uWCa"
      },
      "source": [
        "# Split our DataSet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "drPss_nkuhA4"
      },
      "outputs": [],
      "source": [
        "# y is our target variable employee churn. We drop our target from X.\n",
        "y = df['Churn']\n",
        "X = df.drop(columns=['Churn'])\n",
        "\n",
        "# Use pandas get_dummies function to create dummy variables necessary for statistical interpretation during machine learning.\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Class balancing the target using SMOTE, we will use the minority sampling class strategy since we want to oversample our smaller target variable class.\n",
        "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "# Fit SMOTE to our X and y variables.\n",
        "X, y = sm.fit_resample(X, y)\n",
        "\n",
        "# Splitting dataset into a training set and test set using a test size of 20%.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH7kCPdRC5Zs"
      },
      "source": [
        "Now that we have cleaned our data, and created our target variable while fixing class imbalance, our data is now ready for machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EBJrmXWnNTs"
      },
      "source": [
        "# Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ntl-Xt4_nQpE",
        "outputId": "dd4d252a-9c2b-44f4-fb10-bc738d504568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.865 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Adjust our max iteration value, 100 is too low and gives errors.\n",
        "clf = LogisticRegression(max_iter=400).fit(X_train, y_train)\n",
        "\n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBA2VrR0W5e9"
      },
      "source": [
        "Our logistic regression classifier model ran rather fast without any feature selection or decompostion in about only 0.8 seconds. Logistic regression classification is well-suited for this task as our target variable has a binary output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "yAqMZ8AHob9R",
        "outputId": "31846022-c384-46b3-e8da-3f968c052d5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.77294686, 0.77777778, 0.74637681, 0.75362319, 0.75483092,\n",
              "       0.78623188, 0.78019324, 0.77415459, 0.75453446, 0.79443773])"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cross validation score for Logistic Regression Classifier.\n",
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKNqthtIW9fQ"
      },
      "source": [
        "We are only seeing some minor variance in cross-validation scores which is a good sign. This means our model is expected to generalize new data. We are also not seeing any signs of over-fitting in our cross-validation scoring which would appear as sporadic over-fitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "oJ0LGpK7n8n7",
        "outputId": "a483b5de-be4a-4608-86d9-5d1a879cfd3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7840579710144927\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.80      0.75      0.77      1021\n",
            "         Yes       0.77      0.82      0.79      1049\n",
            "\n",
            "    accuracy                           0.78      2070\n",
            "   macro avg       0.79      0.78      0.78      2070\n",
            "weighted avg       0.79      0.78      0.78      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[765 256]\n",
            " [191 858]]\n"
          ]
        }
      ],
      "source": [
        "# Building classification report for our logistic regression classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEBm9Mn-XD27"
      },
      "source": [
        "Our model is working moderately well in our classification report above. Our classification report metrics do leave room for improvement however with only somewhat above average scoring in precision, accuracy, recall, and f1-score metrics. We are seeing a slight tradeoff in precision and recall values for the two classes. Our confusion matrix also shows a more than desirable number of false positives and false negatives. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iv9UBg9nRJG"
      },
      "source": [
        "# Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KLr9CvppqKC1",
        "outputId": "7abe9626-8830-4f35-a08a-d04bde69a779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 2.205 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Creating gradient boost classifier.\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "# Fitting model to our data.\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn-5U8gGXPmB"
      },
      "source": [
        "We have a slightly longer runtime than our logistic regression classifier above with over 2 seconds runtime for gradient boosting classification. Although this could be interpreted as only 1 second longer runtime, it could also be interpreted as double the runtime. This means that we may see double runtimes with larger datasets. This is something to keep in mind when evaluating model performance and adapting it to larger datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "9O76az4Jqqyg",
        "outputId": "53106bdb-f6ec-4e9c-c79f-89cd72183a73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.86231884, 0.85024155, 0.85024155, 0.83091787, 0.88405797,\n",
              "       0.87198068, 0.85024155, 0.87077295, 0.83192261, 0.87061669])"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cross validation score for Gradient Boosting Classifier.\n",
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgrjuyAKXUvy"
      },
      "source": [
        "Our gradient boosting model is giving us minimal cross-validation variance of about 5%. Cross-validation scoring is also about 9-10% higher than the logistic regression classifier. Cross-validation scoring for gradient boosting classification is not indicative of any overfitting or underfitting with consistent scoring across the ten cross-validations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "egSBiHK8qxrM",
        "outputId": "d36890b2-d7e3-42cd-dfe4-d5027c9eab38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8628019323671497\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.86      0.86      0.86      1021\n",
            "         Yes       0.86      0.87      0.86      1049\n",
            "\n",
            "    accuracy                           0.86      2070\n",
            "   macro avg       0.86      0.86      0.86      2070\n",
            "weighted avg       0.86      0.86      0.86      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[878 143]\n",
            " [141 908]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our Gradient Boosting classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efigNcRBXa4K"
      },
      "source": [
        "Precision, recall, accuracy, and f1-score metrics are all showing better model performance for the gradient boosting classification report compared to logistic regression classification. Precision and recall tradeoff is minor. Our confusion matrix is also showing less false positive and less false negative values.\n",
        "\n",
        "Accuracy is surpassing that of logistic regression by around 8%. However, this model took some additional time to run with over double the runtime so we have a tradeoff in scoring and runtime compared to the logistic regression classification model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa3z5Ac8XzLO"
      },
      "source": [
        "# KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "W4mtAKbwX1lG",
        "outputId": "f44ea4a1-952d-4ff6-8c34-fff724bdc35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.052 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "#Create the KNN Classifier.\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "#Train our model.\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECS4yOGZZXlG"
      },
      "source": [
        "Very fast run time with KNN classifier clocking in at 0.052 seconds using no feature selection or feature decomposition. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "UQHjIcHFYele",
        "outputId": "10494e92-158e-40ac-c432-9497c1c16661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.79227053, 0.77898551, 0.76690821, 0.78140097, 0.77415459,\n",
              "       0.80193237, 0.76086957, 0.78381643, 0.77025393, 0.81620314])"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cross validation score for KNN.\n",
        "cross_val_score(knn, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60iuuIeVZm5a"
      },
      "source": [
        "There is some cross variance of about 5% as seen in the previous classification models. We are also seeing similar but slightly higher cross-validation scoring in comparison to our logistic regression classifier however at a fraction of the runtime. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "fYEaVZ2aYsIb",
        "outputId": "266990d2-97bf-4724-a72f-b575b42c5326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7913043478260869\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.89      0.66      0.76      1021\n",
            "         Yes       0.73      0.92      0.82      1049\n",
            "\n",
            "    accuracy                           0.79      2070\n",
            "   macro avg       0.81      0.79      0.79      2070\n",
            "weighted avg       0.81      0.79      0.79      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[673 348]\n",
            " [ 84 965]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our KNN classifier.\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epO6EB-JZsX7"
      },
      "source": [
        "We are seeing a major tradeoff between precision and recall metrics in both classes of our target variable. This is also shown in the imbalanced confusion matrix, although accuracy scoring is remaining consistent. So although we have reduced our runtime we are also seeing reduced performance in key performance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdvxYkuoZE3j"
      },
      "source": [
        "# SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nNnNqqjhZWn_",
        "outputId": "dcabb6cd-8f93-46be-d5d2-6c18d156c22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 68.297 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "#Create svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train our model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqtiNLB6bz8o"
      },
      "source": [
        "Our SVM model has significantly longer run time than that of our previous models. This is because SVM is a very memory intensive model, and runtime can grow exponentially with increased data size. SVM must make many exhaustive calculations to create the parameters needed for machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "mtgwoUYiZaH7",
        "outputId": "f5471d8d-f2a9-4824-dfa7-1c7d7c57b15b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.75845411, 0.75603865, 0.71014493, 0.71014493, 0.72705314,\n",
              "       0.76328502, 0.76328502, 0.73550725, 0.74607013, 0.78839178])"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cross validation score for SVM.\n",
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvryX9bKb79j"
      },
      "source": [
        "We are seeing some cross-validation score variance of about 7%. This is somewhat higher than previous models. The cross-validation scoring does not show any fitment issues and should be expected to generalize new data however."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "LyobX15TZ3uh",
        "outputId": "e4817e04-a910-4fd8-aa66-428425624e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7541062801932367\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.81      0.65      0.72      1021\n",
            "         Yes       0.72      0.85      0.78      1049\n",
            "\n",
            "    accuracy                           0.75      2070\n",
            "   macro avg       0.76      0.75      0.75      2070\n",
            "weighted avg       0.76      0.75      0.75      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[668 353]\n",
            " [156 893]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our SVM classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "svm_report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(svm_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO_LR_FMCIvy"
      },
      "source": [
        "This does not seem like a good model to use for this dataset with such a long run time and no advantages in cross-validation scoring, variance or classification report metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYB1UOsBUT09"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "raXvqYyzUTXQ",
        "outputId": "7cba6f8b-d225-4f44-b012-ceb92a77c840"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.019310</td>\n",
              "      <td>0.002065</td>\n",
              "      <td>0.003709</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.818841</td>\n",
              "      <td>0.798913</td>\n",
              "      <td>0.832729</td>\n",
              "      <td>0.819335</td>\n",
              "      <td>0.822961</td>\n",
              "      <td>0.818556</td>\n",
              "      <td>0.011017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.034552</td>\n",
              "      <td>0.001213</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.834541</td>\n",
              "      <td>0.795290</td>\n",
              "      <td>0.831522</td>\n",
              "      <td>0.805438</td>\n",
              "      <td>0.825378</td>\n",
              "      <td>0.818434</td>\n",
              "      <td>0.015385</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.034809</td>\n",
              "      <td>0.000669</td>\n",
              "      <td>0.003401</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.828502</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.833937</td>\n",
              "      <td>0.801813</td>\n",
              "      <td>0.825378</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.014773</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.045750</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>0.003374</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.816425</td>\n",
              "      <td>0.798913</td>\n",
              "      <td>0.832126</td>\n",
              "      <td>0.821148</td>\n",
              "      <td>0.817523</td>\n",
              "      <td>0.817227</td>\n",
              "      <td>0.010710</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.061669</td>\n",
              "      <td>0.000852</td>\n",
              "      <td>0.003378</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.820652</td>\n",
              "      <td>0.804952</td>\n",
              "      <td>0.821860</td>\n",
              "      <td>0.810876</td>\n",
              "      <td>0.827190</td>\n",
              "      <td>0.817106</td>\n",
              "      <td>0.008042</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.026212</td>\n",
              "      <td>0.001154</td>\n",
              "      <td>0.003349</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.821860</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.824879</td>\n",
              "      <td>0.816314</td>\n",
              "      <td>0.824773</td>\n",
              "      <td>0.815899</td>\n",
              "      <td>0.012508</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.047074</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.003379</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>0.826691</td>\n",
              "      <td>0.813897</td>\n",
              "      <td>0.812085</td>\n",
              "      <td>0.814085</td>\n",
              "      <td>0.009387</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.021932</td>\n",
              "      <td>0.001544</td>\n",
              "      <td>0.003849</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.817633</td>\n",
              "      <td>0.775966</td>\n",
              "      <td>0.823068</td>\n",
              "      <td>0.810876</td>\n",
              "      <td>0.809668</td>\n",
              "      <td>0.807442</td>\n",
              "      <td>0.016465</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.058782</td>\n",
              "      <td>0.001765</td>\n",
              "      <td>0.003480</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.814010</td>\n",
              "      <td>0.786232</td>\n",
              "      <td>0.810990</td>\n",
              "      <td>0.790937</td>\n",
              "      <td>0.829003</td>\n",
              "      <td>0.806234</td>\n",
              "      <td>0.015720</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.032609</td>\n",
              "      <td>0.001549</td>\n",
              "      <td>0.003471</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.817029</td>\n",
              "      <td>0.772947</td>\n",
              "      <td>0.814614</td>\n",
              "      <td>0.809668</td>\n",
              "      <td>0.813293</td>\n",
              "      <td>0.805510</td>\n",
              "      <td>0.016455</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.027163</td>\n",
              "      <td>0.001203</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.818237</td>\n",
              "      <td>0.786836</td>\n",
              "      <td>0.814010</td>\n",
              "      <td>0.789728</td>\n",
              "      <td>0.818731</td>\n",
              "      <td>0.805508</td>\n",
              "      <td>0.014190</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.028887</td>\n",
              "      <td>0.002306</td>\n",
              "      <td>0.003468</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.800725</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>0.797583</td>\n",
              "      <td>0.815710</td>\n",
              "      <td>0.804180</td>\n",
              "      <td>0.011846</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.042419</td>\n",
              "      <td>0.004660</td>\n",
              "      <td>0.003956</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.790459</td>\n",
              "      <td>0.812198</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.812689</td>\n",
              "      <td>0.803939</td>\n",
              "      <td>0.008272</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.043958</td>\n",
              "      <td>0.005766</td>\n",
              "      <td>0.003467</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.800121</td>\n",
              "      <td>0.789251</td>\n",
              "      <td>0.808575</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.816314</td>\n",
              "      <td>0.803698</td>\n",
              "      <td>0.008997</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.043283</td>\n",
              "      <td>0.001495</td>\n",
              "      <td>0.003452</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.797101</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.806763</td>\n",
              "      <td>0.803625</td>\n",
              "      <td>0.819335</td>\n",
              "      <td>0.802853</td>\n",
              "      <td>0.010566</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.042464</td>\n",
              "      <td>0.001836</td>\n",
              "      <td>0.003456</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.782005</td>\n",
              "      <td>0.808575</td>\n",
              "      <td>0.807855</td>\n",
              "      <td>0.812689</td>\n",
              "      <td>0.802853</td>\n",
              "      <td>0.010856</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.021994</td>\n",
              "      <td>0.001193</td>\n",
              "      <td>0.003457</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.785628</td>\n",
              "      <td>0.807367</td>\n",
              "      <td>0.805438</td>\n",
              "      <td>0.812689</td>\n",
              "      <td>0.802732</td>\n",
              "      <td>0.009171</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.026239</td>\n",
              "      <td>0.002617</td>\n",
              "      <td>0.003399</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.810990</td>\n",
              "      <td>0.768720</td>\n",
              "      <td>0.806159</td>\n",
              "      <td>0.818127</td>\n",
              "      <td>0.806042</td>\n",
              "      <td>0.802008</td>\n",
              "      <td>0.017217</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.033420</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>0.003493</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.799517</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.807367</td>\n",
              "      <td>0.803021</td>\n",
              "      <td>0.816918</td>\n",
              "      <td>0.801886</td>\n",
              "      <td>0.011265</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.056856</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.003615</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.779589</td>\n",
              "      <td>0.808575</td>\n",
              "      <td>0.800604</td>\n",
              "      <td>0.815710</td>\n",
              "      <td>0.801524</td>\n",
              "      <td>0.012129</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.057098</td>\n",
              "      <td>0.000852</td>\n",
              "      <td>0.003395</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.794082</td>\n",
              "      <td>0.796498</td>\n",
              "      <td>0.812802</td>\n",
              "      <td>0.790937</td>\n",
              "      <td>0.812085</td>\n",
              "      <td>0.801281</td>\n",
              "      <td>0.009286</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.058942</td>\n",
              "      <td>0.001290</td>\n",
              "      <td>0.003434</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.795894</td>\n",
              "      <td>0.789855</td>\n",
              "      <td>0.812802</td>\n",
              "      <td>0.794562</td>\n",
              "      <td>0.812689</td>\n",
              "      <td>0.801160</td>\n",
              "      <td>0.009670</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.030946</td>\n",
              "      <td>0.001846</td>\n",
              "      <td>0.003276</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.792874</td>\n",
              "      <td>0.776570</td>\n",
              "      <td>0.814614</td>\n",
              "      <td>0.800604</td>\n",
              "      <td>0.819940</td>\n",
              "      <td>0.800920</td>\n",
              "      <td>0.015537</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.043310</td>\n",
              "      <td>0.001121</td>\n",
              "      <td>0.003441</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.791063</td>\n",
              "      <td>0.809179</td>\n",
              "      <td>0.792145</td>\n",
              "      <td>0.809668</td>\n",
              "      <td>0.800918</td>\n",
              "      <td>0.008019</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.023191</td>\n",
              "      <td>0.001740</td>\n",
              "      <td>0.003588</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.813406</td>\n",
              "      <td>0.780193</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>0.799396</td>\n",
              "      <td>0.810876</td>\n",
              "      <td>0.800436</td>\n",
              "      <td>0.011769</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.022817</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>0.003548</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.769928</td>\n",
              "      <td>0.818237</td>\n",
              "      <td>0.795770</td>\n",
              "      <td>0.812689</td>\n",
              "      <td>0.800436</td>\n",
              "      <td>0.017004</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.077188</td>\n",
              "      <td>0.000926</td>\n",
              "      <td>0.003496</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.803744</td>\n",
              "      <td>0.786232</td>\n",
              "      <td>0.811594</td>\n",
              "      <td>0.788520</td>\n",
              "      <td>0.809063</td>\n",
              "      <td>0.799831</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.040383</td>\n",
              "      <td>0.000894</td>\n",
              "      <td>0.003292</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.777174</td>\n",
              "      <td>0.814614</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.810272</td>\n",
              "      <td>0.799712</td>\n",
              "      <td>0.013545</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.042034</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>0.003450</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.810990</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.798913</td>\n",
              "      <td>0.787311</td>\n",
              "      <td>0.809063</td>\n",
              "      <td>0.799710</td>\n",
              "      <td>0.009214</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.077949</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>0.003493</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.795770</td>\n",
              "      <td>0.813293</td>\n",
              "      <td>0.799590</td>\n",
              "      <td>0.008535</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.032588</td>\n",
              "      <td>0.001705</td>\n",
              "      <td>0.003549</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.791063</td>\n",
              "      <td>0.785628</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.795166</td>\n",
              "      <td>0.822356</td>\n",
              "      <td>0.799471</td>\n",
              "      <td>0.012791</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.033294</td>\n",
              "      <td>0.002173</td>\n",
              "      <td>0.003575</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.807367</td>\n",
              "      <td>0.778986</td>\n",
              "      <td>0.801932</td>\n",
              "      <td>0.792749</td>\n",
              "      <td>0.815710</td>\n",
              "      <td>0.799349</td>\n",
              "      <td>0.012624</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.078765</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.800725</td>\n",
              "      <td>0.785024</td>\n",
              "      <td>0.801329</td>\n",
              "      <td>0.789728</td>\n",
              "      <td>0.816314</td>\n",
              "      <td>0.798624</td>\n",
              "      <td>0.010851</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.018946</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>0.003349</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.772947</td>\n",
              "      <td>0.810386</td>\n",
              "      <td>0.805438</td>\n",
              "      <td>0.799396</td>\n",
              "      <td>0.798503</td>\n",
              "      <td>0.013247</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.032630</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>0.003445</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.803744</td>\n",
              "      <td>0.769324</td>\n",
              "      <td>0.812198</td>\n",
              "      <td>0.798792</td>\n",
              "      <td>0.807251</td>\n",
              "      <td>0.798262</td>\n",
              "      <td>0.015118</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.057804</td>\n",
              "      <td>0.001754</td>\n",
              "      <td>0.003459</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.801329</td>\n",
              "      <td>0.780060</td>\n",
              "      <td>0.806647</td>\n",
              "      <td>0.797655</td>\n",
              "      <td>0.009249</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.021718</td>\n",
              "      <td>0.000725</td>\n",
              "      <td>0.003592</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.786232</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.798792</td>\n",
              "      <td>0.802417</td>\n",
              "      <td>0.797536</td>\n",
              "      <td>0.005970</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.028913</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.003578</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.775362</td>\n",
              "      <td>0.816425</td>\n",
              "      <td>0.789728</td>\n",
              "      <td>0.801813</td>\n",
              "      <td>0.797173</td>\n",
              "      <td>0.013799</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.028566</td>\n",
              "      <td>0.002190</td>\n",
              "      <td>0.003476</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.788043</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.781873</td>\n",
              "      <td>0.807251</td>\n",
              "      <td>0.797173</td>\n",
              "      <td>0.010246</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.056456</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>0.003524</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.792874</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.784894</td>\n",
              "      <td>0.801208</td>\n",
              "      <td>0.796931</td>\n",
              "      <td>0.007066</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.056198</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.003437</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.788647</td>\n",
              "      <td>0.809179</td>\n",
              "      <td>0.781873</td>\n",
              "      <td>0.801813</td>\n",
              "      <td>0.796930</td>\n",
              "      <td>0.010077</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.057021</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>0.003410</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.795290</td>\n",
              "      <td>0.806159</td>\n",
              "      <td>0.778248</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.795480</td>\n",
              "      <td>0.009343</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.078629</td>\n",
              "      <td>0.001174</td>\n",
              "      <td>0.003473</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>44</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.795894</td>\n",
              "      <td>0.779589</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.787311</td>\n",
              "      <td>0.806042</td>\n",
              "      <td>0.794878</td>\n",
              "      <td>0.010302</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.042712</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.003503</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.778382</td>\n",
              "      <td>0.801329</td>\n",
              "      <td>0.787915</td>\n",
              "      <td>0.805438</td>\n",
              "      <td>0.794154</td>\n",
              "      <td>0.009789</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.015868</td>\n",
              "      <td>0.000782</td>\n",
              "      <td>0.003376</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.807367</td>\n",
              "      <td>0.763285</td>\n",
              "      <td>0.790459</td>\n",
              "      <td>0.801813</td>\n",
              "      <td>0.806042</td>\n",
              "      <td>0.793793</td>\n",
              "      <td>0.016374</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.014948</td>\n",
              "      <td>0.002209</td>\n",
              "      <td>0.003308</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.795894</td>\n",
              "      <td>0.780797</td>\n",
              "      <td>0.796498</td>\n",
              "      <td>0.790937</td>\n",
              "      <td>0.801813</td>\n",
              "      <td>0.793188</td>\n",
              "      <td>0.007089</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.023222</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.753623</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.803625</td>\n",
              "      <td>0.807251</td>\n",
              "      <td>0.792465</td>\n",
              "      <td>0.020116</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.042932</td>\n",
              "      <td>0.002489</td>\n",
              "      <td>0.003483</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>30</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.772947</td>\n",
              "      <td>0.800725</td>\n",
              "      <td>0.770997</td>\n",
              "      <td>0.806042</td>\n",
              "      <td>0.789683</td>\n",
              "      <td>0.014718</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "4        0.019310      0.002065  ...        0.011017                1\n",
              "29       0.034552      0.001213  ...        0.015385                2\n",
              "6        0.034809      0.000669  ...        0.014773                3\n",
              "30       0.045750      0.002278  ...        0.010710                4\n",
              "31       0.061669      0.000852  ...        0.008042                5\n",
              "5        0.026212      0.001154  ...        0.012508                6\n",
              "7        0.047074      0.000561  ...        0.009387                7\n",
              "28       0.021932      0.001544  ...        0.016465                8\n",
              "46       0.058782      0.001765  ...        0.015720                9\n",
              "3        0.032609      0.001549  ...        0.016455               10\n",
              "32       0.027163      0.001203  ...        0.014190               11\n",
              "36       0.028887      0.002306  ...        0.011846               12\n",
              "33       0.042419      0.004660  ...        0.008272               13\n",
              "37       0.043958      0.005766  ...        0.008997               14\n",
              "14       0.043283      0.001495  ...        0.010566               15\n",
              "45       0.042464      0.001836  ...        0.010856               16\n",
              "12       0.021994      0.001193  ...        0.009171               17\n",
              "2        0.026239      0.002617  ...        0.017217               18\n",
              "17       0.033420      0.000750  ...        0.011265               19\n",
              "42       0.056856      0.001196  ...        0.012129               20\n",
              "34       0.057098      0.000852  ...        0.009286               21\n",
              "38       0.058942      0.001290  ...        0.009670               22\n",
              "26       0.030946      0.001846  ...        0.015537               23\n",
              "41       0.043310      0.001121  ...        0.008019               24\n",
              "8        0.023191      0.001740  ...        0.011769               25\n",
              "20       0.022817      0.001046  ...        0.017004               26\n",
              "35       0.077188      0.000926  ...        0.010505               27\n",
              "27       0.040383      0.000894  ...        0.013545               28\n",
              "10       0.042034      0.001007  ...        0.009214               29\n",
              "39       0.077949      0.000603  ...        0.008535               30\n",
              "21       0.032588      0.001705  ...        0.012791               31\n",
              "13       0.033294      0.002173  ...        0.012624               32\n",
              "43       0.078765      0.002874  ...        0.010851               33\n",
              "1        0.018946      0.000536  ...        0.013247               34\n",
              "9        0.032630      0.000937  ...        0.015118               35\n",
              "23       0.057804      0.001754  ...        0.009249               36\n",
              "16       0.021718      0.000725  ...        0.005970               37\n",
              "44       0.028913      0.001087  ...        0.013799               38\n",
              "40       0.028566      0.002190  ...        0.010246               39\n",
              "19       0.056456      0.000707  ...        0.007066               40\n",
              "15       0.056198      0.000613  ...        0.010077               41\n",
              "11       0.057021      0.002600  ...        0.009343               42\n",
              "47       0.078629      0.001174  ...        0.010302               43\n",
              "22       0.042712      0.000454  ...        0.009789               44\n",
              "24       0.015868      0.000782  ...        0.016374               45\n",
              "0        0.014948      0.002209  ...        0.007089               46\n",
              "25       0.023222      0.000829  ...        0.020116               47\n",
              "18       0.042932      0.002489  ...        0.014718               48\n",
              "\n",
              "[48 rows x 16 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating initial tree for GridSearchCV to run.\n",
        "decision_tree = tree.DecisionTreeClassifier()\n",
        "\n",
        "# We are looking at a few parameters to see what works best with our model.\n",
        "tree_para = {'criterion':['gini','entropy'],\n",
        "             'max_depth':[5,10,20,50,100,150],\n",
        "             'max_features':[10,20,30,44]}\n",
        "clf = GridSearchCV(decision_tree, tree_para, cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Putting our results into a Pandas DataFrame for easier interpretation.\n",
        "gscv_df = pd.DataFrame(clf.cv_results_)\n",
        "gscv_df.sort_values('rank_test_score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9y_9Dh742W6",
        "outputId": "470972fc-5d2c-447a-cdb3-f904dcb1305c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.028 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize and train our tree using best parameters from GridSearchCV.\n",
        "decision_tree = tree.DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth=10,\n",
        "    max_features=10,\n",
        ")\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Print model runtime. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxqxbsTVR6c-"
      },
      "source": [
        "Decision tree classification is displaying a faster runtime than our KNN classifier, almost half the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDUyMCwPk15r",
        "outputId": "b9fe068c-2f6b-4412-a353-ede5db4dd6fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.82125604, 0.82608696, 0.79347826, 0.78140097, 0.83695652,\n",
              "       0.83695652, 0.8236715 , 0.8321256 , 0.80411125, 0.83675937])"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(decision_tree, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVspYVLRNgv6"
      },
      "source": [
        "Examining cross validation score for our decision tree we are seeing some variance of about 5%, our model is showing no signs of overfitting or underfitting to new data at different cross-validation points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO6tBMTGlPOj",
        "outputId": "1f43bcab-7f7e-4309-8923-053c81fa3681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8227053140096618\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.82      0.83      0.82      1021\n",
            "         Yes       0.83      0.82      0.82      1049\n",
            "\n",
            "    accuracy                           0.82      2070\n",
            "   macro avg       0.82      0.82      0.82      2070\n",
            "weighted avg       0.82      0.82      0.82      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[846 175]\n",
            " [192 857]]\n"
          ]
        }
      ],
      "source": [
        "# Print accuracy score, confusion matrix, and classification report metrics for our Decision Tree.\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test,y_pred)\n",
        "decision_tree_report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", dt_accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(decision_tree_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DWlwc5mbtVy"
      },
      "source": [
        "Weighted average metrics are displaying a similar level of performance as previous models. Accuracy score is desirable considering the runtime reduction. Decision tree classifier is showing the fastest performance so far without features selection or decomposition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBd5wGo1hIyq"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTpRMDGNhNSy",
        "outputId": "f757809d-b6cd-4f19-d698-30eb2d5b0b88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [10, 20, 30, 44],\n",
              "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'n_estimators': [200, 500]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a Random Forest Classifier to use with GridSearchCV.\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "\n",
        "# Creating a parameter grid to find best combination of hyperparameters. \n",
        "param_grid = { \n",
        "    'n_estimators': [200, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [10,20,30,44],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Using GridSearchCV to find best hyperparamater combination.\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "\n",
        "# Fitting GridSearchCV to our newly decomposed data.\n",
        "CV_rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhtWQ3Xj4Vks",
        "outputId": "e09ef64d-a606-4033-a640-f0236103c876"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 20,\n",
              " 'max_features': 'auto',\n",
              " 'n_estimators': 200}"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling best_params_ to find best parameters from GridSearchCV.\n",
        "CV_rfc.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idQq9yxQ4cvs",
        "outputId": "487ded94-a686-4cb1-90a5-97d8c064abc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 2.713 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Creating our model using optimized hyperparameters from GridSearchCV.\n",
        "rfc = ensemble.RandomForestClassifier(criterion='entropy', \n",
        "                                      max_depth=20,\n",
        "                                      max_features='auto',\n",
        "                                      n_estimators=200, random_state=42)\n",
        "\n",
        "# Fit our newly decomposed data to our model.\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv8vooclb386"
      },
      "source": [
        "Random forest classification is running very fast at a time of 2.7 seconds. This indicates that random forest classification is performing moderately well with a manageable runtime in comparison to our faster models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HzDqjfXI75f",
        "outputId": "3cbfe7ee-de5c-4646-d37b-4d0a54a1ec92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.85990338, 0.85386473, 0.84299517, 0.82608696, 0.87318841,\n",
              "       0.87077295, 0.83333333, 0.85628019, 0.85126965, 0.87424426])"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cross-valdiation score for our Random Forest Classifier.\n",
        "cross_val_score(rfc, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDDmymSOqx5M"
      },
      "source": [
        "We are seeing cross-validation variance of around 4% meaning our model is performing consistently and can be expected to handle new data without huge differences in cross-variance scores. We see no signs of overfit or underfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeQot1oTlKvv",
        "outputId": "8271b6f5-86f9-4814-b150-d1479cc5abcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report:\n",
            "Accuracy:  0.8685990338164251\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.85      0.89      0.87      1021\n",
            "         Yes       0.89      0.85      0.87      1049\n",
            "\n",
            "    accuracy                           0.87      2070\n",
            "   macro avg       0.87      0.87      0.87      2070\n",
            "weighted avg       0.87      0.87      0.87      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[905 116]\n",
            " [156 893]]\n"
          ]
        }
      ],
      "source": [
        "# Print classification report for Random Forest Classifier.\n",
        "y_pred = rfc.predict(X_test) \n",
        "rfc_accuracy = accuracy_score(y_test,y_pred)\n",
        "rfc_report = classification_report(y_test, y_pred)\n",
        "rfc_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(\"Accuracy: \", rfc_accuracy)\n",
        "print(rfc_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(rfc_cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRrA-Eiqjp0g"
      },
      "source": [
        "We see some minor tradeoff in our crossvalidation report between precision and recall but to a much smaller degree than the previous machine learning models. Our ensemble model is performing much better than our decision tree model and all other models above. We will research further by looking at feature selection and decomposition methods combined with hyperparameter optimization to fine tune our model performance and get the best results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3eU4hPJGPg_"
      },
      "source": [
        "# Select K Best Feature Selection\n",
        "\n",
        "We can reduce our feature dimensions and choose the most relevant features based on K value with sklearn's SelectKBest function. Let's see if feature selection can improve our runtime or classification report metrics where we had problems with tradeoff between recall and precision earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZmhRlKg10bWn"
      },
      "outputs": [],
      "source": [
        "# Creating target variable.\n",
        "y = df['Churn']\n",
        "\n",
        "# Creating X values by dropping our target.\n",
        "X = df.drop(columns=['Churn'])\n",
        "\n",
        "# Use pandas get_dummies function to create dummy variables necessary for statistical interpretation (One Hot Encoding).\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Run our selector using f_classif for our classification task.\n",
        "selector = SelectKBest(f_classif).fit(X, y)\n",
        "\n",
        "# Create boolean values to select features from original feature set using get_support.\n",
        "boolean = selector.get_support()\n",
        "\n",
        "# Our new X variable now consists of our selected best features based on K value.\n",
        "X_new = X[X.columns[boolean]]\n",
        "\n",
        "# Class balancing using SMOTE.\n",
        "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "# Fitting SMOTE to resample our target class.\n",
        "X_new, y = sm.fit_resample(X_new, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YQGaUpq9JD_b"
      },
      "outputs": [],
      "source": [
        "# Let's split our data, this time using our newly selected features.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.20, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAVUMzDeVVUm",
        "outputId": "eba0041a-e3ff-4361-8a0c-b8389775ab4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7043, 44)"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shape of X before selectkbest is applied.\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQmLtWWFSg4w",
        "outputId": "14bed0f3-49a5-45f0-cb0d-16c41c4b5391"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10348, 10)"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select K best has successfully reduced our number of features from 44 to 10.\n",
        "# We've also synthetically increased our minority class as seen here in the final shape.\n",
        "X_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgf7OPBHse-g"
      },
      "source": [
        "# Logistic Regression Classifier with SelectKBest Feature Selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "h2aNUXJ_sf6n",
        "outputId": "16ef334c-aa0e-4c18-b5b7-6ee33a84906e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.202 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "#Adjust our max iteration value, 100 is too low and gives errors.\n",
        "clf = LogisticRegression(max_iter=400).fit(X_train, y_train)\n",
        "\n",
        "# Print model runtime. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19XQnLtRUuP-"
      },
      "source": [
        "Our run time is much better than before we performed feature selection. We have successfully reduced our run time by about 75% using SelectKBest. This is due to the decreased dimensionality of our new feature set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "ODqSe4UFtX9K",
        "outputId": "eec57421-a190-4151-836f-51ead790007f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.76811594, 0.76086957, 0.73429952, 0.72101449, 0.72705314,\n",
              "       0.77173913, 0.73913043, 0.74516908, 0.74727932, 0.7859734 ])"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print cross validation score.\n",
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWr21I1gVEWf"
      },
      "source": [
        "Logistic regression classification cross-validation scoring is displaying the same attributes before feature selection with no signs of overfitting or underfitting and variance in scoring of about 5%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "Wg2eQmEZteFf",
        "outputId": "223f1cbf-ed69-42bd-e16e-859ae4cca498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7608695652173914\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.79      0.71      0.74      1021\n",
            "         Yes       0.74      0.81      0.78      1049\n",
            "\n",
            "    accuracy                           0.76      2070\n",
            "   macro avg       0.76      0.76      0.76      2070\n",
            "weighted avg       0.76      0.76      0.76      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[722 299]\n",
            " [196 853]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our Logistic Regression Classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKzHShXQtlON"
      },
      "source": [
        "Our models accuracy was reduced by about 2% but this is not a bad trade-off considering the reduction in run-time. This is due to losing some information during feature selection with selectkbest. Precision and recall tradeoff seen here is slightly increased in comparison to our logistic regression classifier before feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxy6p3jbttrD"
      },
      "source": [
        "# Gradient Boosting Classifier with SelectKbest Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2zRoQhbatuol",
        "outputId": "2138a12e-6873-4819-dfc9-ce89aa0fdbbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.536 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Creating gradient boosting classifier.\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "# Fit classifier to training data.\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print model runtime. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Qrf7-hXk-U"
      },
      "source": [
        "SelectKBest feature selection greatly reduced our run time again by about 75%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "yKomHbHpt1yJ",
        "outputId": "0ebd6dad-2db9-459e-ad92-573976035cf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.79468599, 0.76690821, 0.73913043, 0.73792271, 0.75603865,\n",
              "       0.77898551, 0.75603865, 0.75724638, 0.75211608, 0.80169287])"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2SwhpSYXqjh"
      },
      "source": [
        "We are seeing more cross-validation score variance here than our initial gradient boosting classifier without feature selection. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "urXWI0llt8_D",
        "outputId": "e26983c1-f7c2-41d3-e4de-1ab75ee214e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7729468599033816\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.80      0.72      0.76      1021\n",
            "         Yes       0.75      0.83      0.79      1049\n",
            "\n",
            "    accuracy                           0.77      2070\n",
            "   macro avg       0.78      0.77      0.77      2070\n",
            "weighted avg       0.78      0.77      0.77      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[731 290]\n",
            " [180 869]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our Gradient Boosting classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "309LHYMgX06k"
      },
      "source": [
        "Reduction in accuracy and other classification report metrics shows our model performance is lowered due to loss of information during feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_wNVn1XuQN6"
      },
      "source": [
        "# KNN Classifier with SelectKBest Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0Nc1sn3zuW6j",
        "outputId": "9d7481fb-192b-4408-d72a-924e6426952f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.021 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "#Create the KNN Classifier.\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "#Train our model.\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Taqr5lpnaA4K"
      },
      "source": [
        "We further reduced our run time by more than half using selectkbest feature selection. This is due to decreased dimensionality therefore decreased computation time. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "xWwTE8WTudnA",
        "outputId": "d5eedc13-ca3a-4a17-82a5-7a3c9a0667c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.79951691, 0.76207729, 0.76690821, 0.73188406, 0.75241546,\n",
              "       0.77777778, 0.76932367, 0.77173913, 0.75211608, 0.7980653 ])"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(knn, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97jjBfOYa5n2"
      },
      "source": [
        "Our KNN classifer model with feature selection is displaying similar variance before selection of 6% in our cross-validation score. Cross-validation score is not showing any signs of overfitting or underfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "TQjVW1Q3uiqe",
        "outputId": "954fbb6a-e413-41fa-b1a0-c0f75b2bd2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7830917874396135\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.85      0.68      0.75      1021\n",
            "         Yes       0.74      0.89      0.81      1049\n",
            "\n",
            "    accuracy                           0.78      2070\n",
            "   macro avg       0.80      0.78      0.78      2070\n",
            "weighted avg       0.79      0.78      0.78      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[691 330]\n",
            " [119 930]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our KNN classifier.\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRf7kVoo7hj_"
      },
      "source": [
        "We are seeing very similar performance with this model to the KNN classification model before feature selection. Weighted average scoring for precision, recall, and f1-score are reduced by a couple of points. This seems to be worth the tradeoff of redcing model runtime by half."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3D63tSFu3hv"
      },
      "source": [
        "# SVM Classifier with SelectKBest Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OYk68KH8u8-H",
        "outputId": "2e6cae01-bb94-4738-ac74-c8ff71062ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 3.097 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "#Create SVM Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train our model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDU-TNM0cc1A"
      },
      "source": [
        "We have a much better run time than that of our initial model of around 60 seconds, reducing runtime by a minute woth selectkbest feature selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "YUi_iG1vvCIa",
        "outputId": "f95d4d9a-0de2-40e2-8dc4-9449b853e182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.75966184, 0.75362319, 0.7089372 , 0.70289855, 0.71980676,\n",
              "       0.75603865, 0.75      , 0.72705314, 0.73518742, 0.77750907])"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjwV_tL9cjXh"
      },
      "source": [
        "Cross-validation score variance is about the same around 7%. Cross-validation scoring shows no signs of overfitting or underfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "xrA69cFNvIPY",
        "outputId": "11d15611-f760-4581-f1da-4aa512ac2c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7463768115942029\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.80      0.65      0.72      1021\n",
            "         Yes       0.71      0.84      0.77      1049\n",
            "\n",
            "    accuracy                           0.75      2070\n",
            "   macro avg       0.75      0.75      0.74      2070\n",
            "weighted avg       0.75      0.75      0.74      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[668 353]\n",
            " [172 877]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our SVM classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "svm_report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(svm_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9LMg3locuW2"
      },
      "source": [
        "We have a minor loss in accuracy of about 1% compared to before feature selection with selectkbest. This is a great tradeoff for such a dramatic reduction in runtime and shows how effective feature selection is in some use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttFXYdW8c6GA"
      },
      "source": [
        "# Decision Tree Classifier with SelectKBest Selected Features and Optimized Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "45j1oRToKKCp",
        "outputId": "eaa0f0ae-71d9-4f19-dcda-ff11e37c6f3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.020605</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.834541</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.813293</td>\n",
              "      <td>0.825378</td>\n",
              "      <td>0.818797</td>\n",
              "      <td>0.017413</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.002210</td>\n",
              "      <td>0.003316</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.814010</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.816425</td>\n",
              "      <td>0.823565</td>\n",
              "      <td>0.815710</td>\n",
              "      <td>0.812275</td>\n",
              "      <td>0.010809</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.013329</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>0.003262</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.815217</td>\n",
              "      <td>0.783816</td>\n",
              "      <td>0.826691</td>\n",
              "      <td>0.801813</td>\n",
              "      <td>0.822961</td>\n",
              "      <td>0.810100</td>\n",
              "      <td>0.015661</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.015925</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.003470</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.816425</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.808575</td>\n",
              "      <td>0.810272</td>\n",
              "      <td>0.804834</td>\n",
              "      <td>0.803577</td>\n",
              "      <td>0.013432</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.016222</td>\n",
              "      <td>0.000835</td>\n",
              "      <td>0.003416</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.801932</td>\n",
              "      <td>0.783213</td>\n",
              "      <td>0.823068</td>\n",
              "      <td>0.795770</td>\n",
              "      <td>0.810272</td>\n",
              "      <td>0.802851</td>\n",
              "      <td>0.013420</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.014075</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>0.003298</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.810386</td>\n",
              "      <td>0.781401</td>\n",
              "      <td>0.824879</td>\n",
              "      <td>0.788520</td>\n",
              "      <td>0.809063</td>\n",
              "      <td>0.802850</td>\n",
              "      <td>0.015787</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.016497</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>0.003357</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.807367</td>\n",
              "      <td>0.771135</td>\n",
              "      <td>0.814010</td>\n",
              "      <td>0.804834</td>\n",
              "      <td>0.815710</td>\n",
              "      <td>0.802611</td>\n",
              "      <td>0.016247</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.026972</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.003483</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>0.783213</td>\n",
              "      <td>0.806763</td>\n",
              "      <td>0.804834</td>\n",
              "      <td>0.819335</td>\n",
              "      <td>0.802491</td>\n",
              "      <td>0.011804</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011328</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.003281</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.820048</td>\n",
              "      <td>0.777174</td>\n",
              "      <td>0.794082</td>\n",
              "      <td>0.811480</td>\n",
              "      <td>0.809668</td>\n",
              "      <td>0.802490</td>\n",
              "      <td>0.015180</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.022232</td>\n",
              "      <td>0.000967</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.793478</td>\n",
              "      <td>0.792874</td>\n",
              "      <td>0.815821</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.821148</td>\n",
              "      <td>0.801764</td>\n",
              "      <td>0.014040</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.027536</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.003453</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.789855</td>\n",
              "      <td>0.815821</td>\n",
              "      <td>0.798187</td>\n",
              "      <td>0.812689</td>\n",
              "      <td>0.801644</td>\n",
              "      <td>0.010709</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.028528</td>\n",
              "      <td>0.000514</td>\n",
              "      <td>0.003434</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.796498</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.803744</td>\n",
              "      <td>0.794562</td>\n",
              "      <td>0.822356</td>\n",
              "      <td>0.800920</td>\n",
              "      <td>0.011910</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.012118</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.003294</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.795894</td>\n",
              "      <td>0.785024</td>\n",
              "      <td>0.820652</td>\n",
              "      <td>0.803625</td>\n",
              "      <td>0.795770</td>\n",
              "      <td>0.800193</td>\n",
              "      <td>0.011819</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.013015</td>\n",
              "      <td>0.000322</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.801329</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.816425</td>\n",
              "      <td>0.793958</td>\n",
              "      <td>0.806042</td>\n",
              "      <td>0.800072</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.017168</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>0.003516</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.804952</td>\n",
              "      <td>0.783816</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.802417</td>\n",
              "      <td>0.804834</td>\n",
              "      <td>0.799711</td>\n",
              "      <td>0.008021</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.021257</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.003627</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.795894</td>\n",
              "      <td>0.789251</td>\n",
              "      <td>0.795290</td>\n",
              "      <td>0.807251</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.797537</td>\n",
              "      <td>0.005947</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.016280</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>0.003411</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.803744</td>\n",
              "      <td>0.802417</td>\n",
              "      <td>0.796375</td>\n",
              "      <td>0.797174</td>\n",
              "      <td>0.010176</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.029423</td>\n",
              "      <td>0.004131</td>\n",
              "      <td>0.003612</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.801329</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.800725</td>\n",
              "      <td>0.796979</td>\n",
              "      <td>0.799396</td>\n",
              "      <td>0.797173</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.015763</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>0.003466</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.807367</td>\n",
              "      <td>0.782005</td>\n",
              "      <td>0.818841</td>\n",
              "      <td>0.790937</td>\n",
              "      <td>0.786103</td>\n",
              "      <td>0.797050</td>\n",
              "      <td>0.013891</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.019401</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>0.003492</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.801932</td>\n",
              "      <td>0.786232</td>\n",
              "      <td>0.810386</td>\n",
              "      <td>0.796375</td>\n",
              "      <td>0.786707</td>\n",
              "      <td>0.796326</td>\n",
              "      <td>0.009204</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.018918</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.003457</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.777174</td>\n",
              "      <td>0.788647</td>\n",
              "      <td>0.793353</td>\n",
              "      <td>0.817523</td>\n",
              "      <td>0.794881</td>\n",
              "      <td>0.013231</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.019247</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.003430</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.800121</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.791063</td>\n",
              "      <td>0.793958</td>\n",
              "      <td>0.797583</td>\n",
              "      <td>0.794878</td>\n",
              "      <td>0.003479</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.020414</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.003510</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.795290</td>\n",
              "      <td>0.779589</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.784894</td>\n",
              "      <td>0.810272</td>\n",
              "      <td>0.794516</td>\n",
              "      <td>0.011212</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.018013</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.003454</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.778382</td>\n",
              "      <td>0.810990</td>\n",
              "      <td>0.796375</td>\n",
              "      <td>0.790937</td>\n",
              "      <td>0.793791</td>\n",
              "      <td>0.010492</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.013942</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.003587</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.803744</td>\n",
              "      <td>0.786232</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.792749</td>\n",
              "      <td>0.792749</td>\n",
              "      <td>0.793549</td>\n",
              "      <td>0.005664</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.021878</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.003502</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.800121</td>\n",
              "      <td>0.771135</td>\n",
              "      <td>0.794686</td>\n",
              "      <td>0.801208</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.793430</td>\n",
              "      <td>0.011376</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.016478</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.003441</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.807971</td>\n",
              "      <td>0.780797</td>\n",
              "      <td>0.786232</td>\n",
              "      <td>0.802417</td>\n",
              "      <td>0.789728</td>\n",
              "      <td>0.793429</td>\n",
              "      <td>0.010172</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.015154</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.003502</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>0.784420</td>\n",
              "      <td>0.797101</td>\n",
              "      <td>0.796375</td>\n",
              "      <td>0.790332</td>\n",
              "      <td>0.793308</td>\n",
              "      <td>0.005228</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.015048</td>\n",
              "      <td>0.001714</td>\n",
              "      <td>0.003658</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.800725</td>\n",
              "      <td>0.748188</td>\n",
              "      <td>0.815217</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.794562</td>\n",
              "      <td>0.792584</td>\n",
              "      <td>0.023191</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.014001</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.003402</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>gini</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 150, 'max_f...</td>\n",
              "      <td>0.800121</td>\n",
              "      <td>0.786836</td>\n",
              "      <td>0.799517</td>\n",
              "      <td>0.793353</td>\n",
              "      <td>0.783082</td>\n",
              "      <td>0.792582</td>\n",
              "      <td>0.006765</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.017376</td>\n",
              "      <td>0.000728</td>\n",
              "      <td>0.003430</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.773551</td>\n",
              "      <td>0.804952</td>\n",
              "      <td>0.801813</td>\n",
              "      <td>0.784894</td>\n",
              "      <td>0.791496</td>\n",
              "      <td>0.011434</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.015245</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.003461</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.788647</td>\n",
              "      <td>0.762077</td>\n",
              "      <td>0.811594</td>\n",
              "      <td>0.789124</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.791134</td>\n",
              "      <td>0.016998</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.017511</td>\n",
              "      <td>0.000564</td>\n",
              "      <td>0.003455</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>entropy</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
              "      <td>0.785628</td>\n",
              "      <td>0.777174</td>\n",
              "      <td>0.803140</td>\n",
              "      <td>0.792749</td>\n",
              "      <td>0.794562</td>\n",
              "      <td>0.790651</td>\n",
              "      <td>0.008747</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.021632</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>0.003490</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.795290</td>\n",
              "      <td>0.767512</td>\n",
              "      <td>0.807367</td>\n",
              "      <td>0.786103</td>\n",
              "      <td>0.796375</td>\n",
              "      <td>0.790529</td>\n",
              "      <td>0.013340</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.020342</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.003478</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>entropy</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 50, 'max...</td>\n",
              "      <td>0.795894</td>\n",
              "      <td>0.775362</td>\n",
              "      <td>0.802536</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.792749</td>\n",
              "      <td>0.790408</td>\n",
              "      <td>0.009307</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.014144</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>0.003397</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>gini</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n",
              "      <td>0.800725</td>\n",
              "      <td>0.757850</td>\n",
              "      <td>0.801329</td>\n",
              "      <td>0.798187</td>\n",
              "      <td>0.792749</td>\n",
              "      <td>0.790168</td>\n",
              "      <td>0.016440</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.016535</td>\n",
              "      <td>0.002062</td>\n",
              "      <td>0.003465</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.794082</td>\n",
              "      <td>0.766304</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.781269</td>\n",
              "      <td>0.807251</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.013723</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.014273</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.796498</td>\n",
              "      <td>0.763285</td>\n",
              "      <td>0.791063</td>\n",
              "      <td>0.786103</td>\n",
              "      <td>0.803625</td>\n",
              "      <td>0.788115</td>\n",
              "      <td>0.013712</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.018174</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.003886</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>entropy</td>\n",
              "      <td>150</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 150, 'ma...</td>\n",
              "      <td>0.791063</td>\n",
              "      <td>0.762681</td>\n",
              "      <td>0.793478</td>\n",
              "      <td>0.795166</td>\n",
              "      <td>0.796979</td>\n",
              "      <td>0.787873</td>\n",
              "      <td>0.012746</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.015482</td>\n",
              "      <td>0.000775</td>\n",
              "      <td>0.003937</td>\n",
              "      <td>0.000951</td>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 100, 'max_f...</td>\n",
              "      <td>0.800121</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.794686</td>\n",
              "      <td>0.793353</td>\n",
              "      <td>0.787915</td>\n",
              "      <td>0.787389</td>\n",
              "      <td>0.013816</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.014857</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.003523</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>gini</td>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.766304</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>0.789728</td>\n",
              "      <td>0.796375</td>\n",
              "      <td>0.786665</td>\n",
              "      <td>0.011578</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.017140</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.003442</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 100, 'ma...</td>\n",
              "      <td>0.786836</td>\n",
              "      <td>0.752415</td>\n",
              "      <td>0.798913</td>\n",
              "      <td>0.810272</td>\n",
              "      <td>0.781873</td>\n",
              "      <td>0.786062</td>\n",
              "      <td>0.019501</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.010555</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.003176</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.790459</td>\n",
              "      <td>0.762077</td>\n",
              "      <td>0.775966</td>\n",
              "      <td>0.780060</td>\n",
              "      <td>0.789124</td>\n",
              "      <td>0.779537</td>\n",
              "      <td>0.010287</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010593</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.003334</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.791063</td>\n",
              "      <td>0.748188</td>\n",
              "      <td>0.765097</td>\n",
              "      <td>0.784290</td>\n",
              "      <td>0.789728</td>\n",
              "      <td>0.775673</td>\n",
              "      <td>0.016589</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.011176</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.753019</td>\n",
              "      <td>0.739734</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>0.783686</td>\n",
              "      <td>0.793353</td>\n",
              "      <td>0.773620</td>\n",
              "      <td>0.023121</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.010507</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.003150</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.792874</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.754683</td>\n",
              "      <td>0.770717</td>\n",
              "      <td>0.020503</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.010399</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.003164</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.787440</td>\n",
              "      <td>0.747585</td>\n",
              "      <td>0.794082</td>\n",
              "      <td>0.774622</td>\n",
              "      <td>0.747432</td>\n",
              "      <td>0.770232</td>\n",
              "      <td>0.019580</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009642</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.003236</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.780193</td>\n",
              "      <td>0.736715</td>\n",
              "      <td>0.782005</td>\n",
              "      <td>0.783082</td>\n",
              "      <td>0.757704</td>\n",
              "      <td>0.767940</td>\n",
              "      <td>0.018204</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "31       0.020605      0.000654  ...        0.017413                1\n",
              "7        0.019417      0.002210  ...        0.010809                2\n",
              "6        0.013329      0.000474  ...        0.015661                3\n",
              "10       0.015925      0.000396  ...        0.013432                4\n",
              "32       0.016222      0.000835  ...        0.013420                5\n",
              "29       0.014075      0.000556  ...        0.015787                6\n",
              "30       0.016497      0.001058  ...        0.016247                7\n",
              "39       0.026972      0.000811  ...        0.011804                8\n",
              "4        0.011328      0.000208  ...        0.015180                9\n",
              "23       0.022232      0.000967  ...        0.014040               10\n",
              "35       0.027536      0.001183  ...        0.010709               11\n",
              "43       0.028528      0.000514  ...        0.011910               12\n",
              "5        0.012118      0.000202  ...        0.011819               13\n",
              "28       0.013015      0.000322  ...        0.011375               14\n",
              "36       0.017168      0.000819  ...        0.008021               15\n",
              "11       0.021257      0.000599  ...        0.005947               16\n",
              "18       0.016280      0.000507  ...        0.010176               17\n",
              "47       0.029423      0.004131  ...        0.005091               18\n",
              "14       0.015763      0.000687  ...        0.013891               19\n",
              "37       0.019401      0.001554  ...        0.009204               20\n",
              "34       0.018918      0.000412  ...        0.013231               21\n",
              "42       0.019247      0.000352  ...        0.003479               22\n",
              "46       0.020414      0.001032  ...        0.011212               23\n",
              "41       0.018013      0.000208  ...        0.010492               24\n",
              "16       0.013942      0.000392  ...        0.005664               25\n",
              "19       0.021878      0.001087  ...        0.011376               26\n",
              "22       0.016478      0.000312  ...        0.010172               27\n",
              "21       0.015154      0.000292  ...        0.005228               28\n",
              "3        0.015048      0.001714  ...        0.023191               29\n",
              "20       0.014001      0.000390  ...        0.006765               30\n",
              "44       0.017376      0.000728  ...        0.011434               31\n",
              "9        0.015245      0.000526  ...        0.016998               32\n",
              "33       0.017511      0.000564  ...        0.008747               33\n",
              "15       0.021632      0.001084  ...        0.013340               34\n",
              "38       0.020342      0.000569  ...        0.009307               35\n",
              "8        0.014144      0.000424  ...        0.016440               36\n",
              "27       0.016535      0.002062  ...        0.013723               37\n",
              "12       0.014273      0.000615  ...        0.013712               38\n",
              "45       0.018174      0.000483  ...        0.012746               39\n",
              "17       0.015482      0.000775  ...        0.013816               40\n",
              "13       0.014857      0.000411  ...        0.011578               41\n",
              "40       0.017140      0.000331  ...        0.019501               42\n",
              "2        0.010555      0.000333  ...        0.010287               43\n",
              "1        0.010593      0.000712  ...        0.016589               44\n",
              "26       0.011176      0.000234  ...        0.023121               45\n",
              "25       0.010507      0.000370  ...        0.020503               46\n",
              "24       0.010399      0.000454  ...        0.019580               47\n",
              "0        0.009642      0.000250  ...        0.018204               48\n",
              "\n",
              "[48 rows x 16 columns]"
            ]
          },
          "execution_count": 85,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We are looking at a few parameters to see what works best with our model.\n",
        "tree_para = {'criterion':['gini','entropy'],\n",
        "             'max_depth':[5,10,20,50,100,150],\n",
        "             'max_features':[3,4,5,10]}\n",
        "clf = GridSearchCV(decision_tree, tree_para, cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Putting our results into a Pandas DataFrame for easier interpretation.\n",
        "gscv_df = pd.DataFrame(clf.cv_results_)\n",
        "gscv_df.sort_values('rank_test_score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36xicDgkOoJ4"
      },
      "source": [
        "We've ordered the DataFrame above containing the results of our parameter grid search with GridSearchCV by test rank. We can pick the top row for our best parameters and run the model again with our new hyperparameters to see how our model performs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bw0GE6Yc0W4",
        "outputId": "8515f576-bb25-4d98-f929-0d0a54e78748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.032 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize and train our tree using best parameters from GridSearchCV.\n",
        "decision_tree = tree.DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_depth=10,\n",
        "    max_features=10,\n",
        ")\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFKJEI3MelNs"
      },
      "source": [
        "The runtime here with selectkbest feature selection is reduced by over half compared to our initial model without feature selection and optimized hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIjlISczexQy",
        "outputId": "a128711a-411f-4db7-bf79-570712d51456"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.81642512, 0.81038647, 0.79468599, 0.79589372, 0.8236715 ,\n",
              "       0.81400966, 0.8031401 , 0.82971014, 0.80169287, 0.83192261])"
            ]
          },
          "execution_count": 87,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print cross-validation score.\n",
        "cross_val_score(decision_tree, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1SzBjZDSRLg"
      },
      "source": [
        "Cross-validation scoring is varying around in a range of around 4%, and showing no signs of overfitting or underfitting. This is an improvement from our initial model as well as we are not seeing as much variance in cross-validation scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CR3_Is0yLGL",
        "outputId": "628a9824-d65e-47b7-bbb3-2c8dd2a80209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8289855072463768\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.83      0.82      0.82      1021\n",
            "         Yes       0.83      0.84      0.83      1049\n",
            "\n",
            "    accuracy                           0.83      2070\n",
            "   macro avg       0.83      0.83      0.83      2070\n",
            "weighted avg       0.83      0.83      0.83      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[834 187]\n",
            " [167 882]]\n"
          ]
        }
      ],
      "source": [
        "# Creating classification report.\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test,y_pred)\n",
        "decision_tree_report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", dt_accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(decision_tree_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXgoAP-b1JvT"
      },
      "source": [
        "We were able to increase our models accuracy by 1% while also reducing our runtime by over half. This shows how selectkbest can be used to reduce runtime by decreasing feature dimensionality while maintaining model performance when feature selection is performed correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtknzVWL1gZA"
      },
      "source": [
        "# Random Forest Classifier with SelectKBest Selected Features and Optimized Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVB_BgQAjcZ3",
        "outputId": "75aa5050-2709-481e-8ac2-02a4e18a828a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [4, 6, 8, 10],\n",
              "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'n_estimators': [200, 500]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a Random Forest Classifier to use with GridSearchCV.\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "\n",
        "# Creating a parameter grid to find best combination of hyperparameters. \n",
        "param_grid = { \n",
        "    'n_estimators': [200, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [4,6,8,10],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Using GridSearchCV to find best hyperparamater combination.\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "\n",
        "# Fitting GridSearchCV to our newly decomposed data.\n",
        "CV_rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlBwRlRgjc8I",
        "outputId": "1ebde745-3745-400b-a5d9-60cace46a594"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 10,\n",
              " 'max_features': 'sqrt',\n",
              " 'n_estimators': 500}"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling best_params_ to find best parameters from GridSearchCV.\n",
        "CV_rfc.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzC67Fiy1cYq",
        "outputId": "2654a686-87ba-4bfa-950c-58094ec3ca30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 2.488 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Creating our model using optimized hyperparameters from GridSearchCV.\n",
        "rfc = ensemble.RandomForestClassifier(criterion='gini', \n",
        "                                      max_depth=10,\n",
        "                                      max_features='sqrt',\n",
        "                                      n_estimators=500, random_state=42)\n",
        "\n",
        "# Fit our newly decomposed data to our model.\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMPpPsZDIf38"
      },
      "source": [
        "Using selectkbest selected features decreased runtime for the random forest classification task as expected although it may not be enough of a reduction in runtime to justify any impact on classification report scoring. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc8x3Sc-J8v7",
        "outputId": "f9c32fc2-3738-49f9-e35b-626446aa8ad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.82729469, 0.79951691, 0.76932367, 0.76328502, 0.79830918,\n",
              "       0.81884058, 0.7910628 , 0.80193237, 0.79081016, 0.8210399 ])"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print cross-validation score.\n",
        "cross_val_score(rfc, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIHf-gouqhKf"
      },
      "source": [
        "Cross-validation scoring is displaying variance of around 6% with no signs of overfitting or underfitting. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ69YUdzAD1B",
        "outputId": "be585bff-2387-409e-e7d2-443a3731cf2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report:\n",
            "Accuracy:  0.8169082125603865\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.87      0.74      0.80      1021\n",
            "         Yes       0.78      0.89      0.83      1049\n",
            "\n",
            "    accuracy                           0.82      2070\n",
            "   macro avg       0.82      0.82      0.82      2070\n",
            "weighted avg       0.82      0.82      0.82      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[759 262]\n",
            " [117 932]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = rfc.predict(X_test) \n",
        "rfc_accuracy = accuracy_score(y_test,y_pred)\n",
        "rfc_report = classification_report(y_test, y_pred)\n",
        "rfc_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(\"Accuracy: \", rfc_accuracy)\n",
        "print(rfc_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(rfc_cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP6X0wn8CpOl"
      },
      "source": [
        "Selectkbest didn't improve our outcome here in terms of model runtime or model performance as seen here in our classification report metrics, with weighted averages lower in precision, recall, f1-score. We will try feature decomposition instead of selection when creating a random forest ensemble model next to improve model performance. This is due to this model losing information that our random forest model can easily interpret while selecting k best features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zD9bSymkFgx"
      },
      "source": [
        "# PCA Feature Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KB_Jrw0Do6E9"
      },
      "outputs": [],
      "source": [
        "y = df['Churn']\n",
        "X = df.drop(columns=['Churn'])\n",
        "\n",
        "# Use pandas get_dummies function to create dummy variables necessary for statistical interpretation (one hot encoding).\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Apply SMOTE to fix class imbalance.\n",
        "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "X, y = sm.fit_resample(X, y)\n",
        "\n",
        "# First we must scale our data so that it can be fit into our PCA model.\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA to our scaled data.\n",
        "sklearn_pca = PCA(n_components = 0.95)\n",
        "X_pca = sklearn_pca.fit_transform(scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiA4E06D7SW4",
        "outputId": "92ea89b0-faf3-492b-bf90-b5dfd2fc922a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10348, 44)"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify dimensionality reduction.\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twvyw-hY37Jp",
        "outputId": "f1678137-bc4c-4e75-d171-c2556c6e94a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10348, 18)"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PCA has reduced our number of features to 18 to explain 95% of variance.\n",
        "X_pca.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FeeJ_TwTCweJ"
      },
      "outputs": [],
      "source": [
        "# Split PCA data.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.20, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYY082d0zKTI"
      },
      "source": [
        "# Logistic Regression Classifier with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XUccnwbIzRNx",
        "outputId": "cdf3c2a3-59c7-4240-9238-ec0a40779c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.064 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Create and fit our Logistic Regression classifier.\n",
        "clf = LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1EQF4puVpIP"
      },
      "source": [
        "This model has the best run time out of our earlier models with selectkbest and no feature selection. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "9uE5AmbwzZv5",
        "outputId": "5e7ad5c4-fbfb-48c3-de63-c989b86a4bcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.7705314 , 0.78019324, 0.73309179, 0.74396135, 0.75603865,\n",
              "       0.78743961, 0.77536232, 0.77536232, 0.74727932, 0.78839178])"
            ]
          },
          "execution_count": 57,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print cross-validation score.\n",
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvRs5arcWT2N"
      },
      "source": [
        "We see not a lot of variance here which is good. Let's compare our classification report to our first model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "hT--wlYjzeuP",
        "outputId": "7aac8e6a-1326-4590-ae73-ff30f9041354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7840579710144927\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.80      0.75      0.77      1021\n",
            "         Yes       0.77      0.82      0.79      1049\n",
            "\n",
            "    accuracy                           0.78      2070\n",
            "   macro avg       0.78      0.78      0.78      2070\n",
            "weighted avg       0.78      0.78      0.78      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[768 253]\n",
            " [194 855]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our Logistic Regression classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNLq-GBXWcxr"
      },
      "source": [
        "Due to our new features from PCA accounting for about 95% of variance in our dataset we are seeing the same accuracy as before feature selection at a fraction of the run-time. PCA is optimal here as it allows for the quickest run-time and no reduction in accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmfxVesj0J5D"
      },
      "source": [
        "# Gradient Boosting Classifier with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "q9p3rgbe0OfV",
        "outputId": "5390ca37-20a6-4ab1-9a2b-7884dca94f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 5.583 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Create our Gradient Boosting Classifier.\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "# Fit classifier to newly decomposed data.\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqXWwJPVYBG3"
      },
      "source": [
        "Our model run time is longer than both our initial and selectkbest run times. This model performs best with raw data it seems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "UNV0QHe80SBC",
        "outputId": "066650a1-1fc6-41e4-bc2e-81dcef1a6f5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.81400966, 0.80917874, 0.76086957, 0.7705314 , 0.79710145,\n",
              "       0.81280193, 0.79710145, 0.79830918, 0.77509069, 0.81499395])"
            ]
          },
          "execution_count": 60,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print cross-validation score.\n",
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "Ax4f-SId0W2N",
        "outputId": "064ef9b7-4e9f-45ef-aa87-9b764f0b0ff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8077294685990338\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.83      0.77      0.80      1021\n",
            "         Yes       0.79      0.84      0.82      1049\n",
            "\n",
            "    accuracy                           0.81      2070\n",
            "   macro avg       0.81      0.81      0.81      2070\n",
            "weighted avg       0.81      0.81      0.81      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[790 231]\n",
            " [167 882]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our Gradient Boosting classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cjVJWY50ntH"
      },
      "source": [
        "Our model is performing better than when we used selectkbest feature selection. This is due to our new features accounting for most of our datasets variance. However our model is not performing as well as our initial model and has a longer run time (about 3x)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ73YKG30wRd"
      },
      "source": [
        "# KNN Classifier with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kmtYP2H201X9",
        "outputId": "d82a187c-c035-4288-fc36-f9796ca5a1d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.033 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "#Create the KNN Classifier.\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "#Train our model.\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQpPYRuXbDhO"
      },
      "source": [
        "We have slightly longer run time than selectkbest selected features but less run time than our initial model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "DO9yrGhJ04YL",
        "outputId": "c11db12c-4aaa-4080-bcb6-22b6c2dbc546"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.77536232, 0.76328502, 0.74516908, 0.75      , 0.77898551,\n",
              "       0.7826087 , 0.7705314 , 0.77173913, 0.77629988, 0.7859734 ])"
            ]
          },
          "execution_count": 63,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(knn, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI3xVGiRbNiH"
      },
      "source": [
        "This model gives us the best cross-validation score variance out of all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "9MLPwcGb060z",
        "outputId": "5e2ccff6-7ede-4e2e-9e8f-22fbe0447c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7888888888888889\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.87      0.67      0.76      1021\n",
            "         Yes       0.74      0.90      0.81      1049\n",
            "\n",
            "    accuracy                           0.79      2070\n",
            "   macro avg       0.80      0.79      0.79      2070\n",
            "weighted avg       0.80      0.79      0.79      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[689 332]\n",
            " [105 944]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our KNN classifier.\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa6TFo13bRxK"
      },
      "source": [
        "We have better accuracy with this model using decomposed features than selectkbest selected features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-jPwZYh1Fgh"
      },
      "source": [
        "# SVM Classifier with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "AVCw_b3F1GaQ",
        "outputId": "4a39a0ef-f929-4df1-bc6b-28489bb91c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 5.134 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "#Create SVM Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train our model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EHJ-CHvc71Q"
      },
      "source": [
        "We are seeing a slightly longer runtime by a couple of seconds here than with feature selection. This is due to more information needing processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "w3bjM_AU1Jms",
        "outputId": "adda35e4-a177-485c-b0f8-835625e5c029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.75362319, 0.76690821, 0.72826087, 0.73671498, 0.73913043,\n",
              "       0.78623188, 0.77415459, 0.76086957, 0.7617896 , 0.80169287])"
            ]
          },
          "execution_count": 66,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(clf, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2kSwmVFc9nq"
      },
      "source": [
        "Cross-validation variance is about the same around 7%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ZI0hGAzu1NwT",
        "outputId": "238ff6e9-4961-470d-82d9-379f1b2ef5fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7792270531400967\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.81      0.72      0.76      1021\n",
            "         Yes       0.75      0.84      0.79      1049\n",
            "\n",
            "    accuracy                           0.78      2070\n",
            "   macro avg       0.78      0.78      0.78      2070\n",
            "weighted avg       0.78      0.78      0.78      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[732 289]\n",
            " [168 881]]\n"
          ]
        }
      ],
      "source": [
        "# Classification report for our SVM classifier.\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "svm_report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification report:\")\n",
        "print(svm_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpFnfbgEdSKs"
      },
      "source": [
        "Using PCA increased our models accuracy by about 3% compared to feature selection. We've also managed to outperform our inital model without any feature selection or decomposition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AqpF47nH25t"
      },
      "source": [
        "# Decision Tree Model with PCA and GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WdBywvb_F7C-",
        "outputId": "afb5512c-d14d-4406-b31e-30f62e336b56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.133932</td>\n",
              "      <td>0.001346</td>\n",
              "      <td>0.003648</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>18</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.772947</td>\n",
              "      <td>0.737319</td>\n",
              "      <td>0.764493</td>\n",
              "      <td>0.774018</td>\n",
              "      <td>0.775227</td>\n",
              "      <td>0.764801</td>\n",
              "      <td>0.014250</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.077481</td>\n",
              "      <td>0.000836</td>\n",
              "      <td>0.003212</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.766908</td>\n",
              "      <td>0.732488</td>\n",
              "      <td>0.756643</td>\n",
              "      <td>0.777644</td>\n",
              "      <td>0.768580</td>\n",
              "      <td>0.760452</td>\n",
              "      <td>0.015491</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.246913</td>\n",
              "      <td>0.004190</td>\n",
              "      <td>0.003206</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>18</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.765097</td>\n",
              "      <td>0.727657</td>\n",
              "      <td>0.762077</td>\n",
              "      <td>0.775227</td>\n",
              "      <td>0.756495</td>\n",
              "      <td>0.757311</td>\n",
              "      <td>0.016027</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.077568</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>0.003165</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>gini</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
              "      <td>0.768720</td>\n",
              "      <td>0.725845</td>\n",
              "      <td>0.759058</td>\n",
              "      <td>0.767976</td>\n",
              "      <td>0.757704</td>\n",
              "      <td>0.755861</td>\n",
              "      <td>0.015663</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.048760</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.003199</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>0.728865</td>\n",
              "      <td>0.763285</td>\n",
              "      <td>0.752266</td>\n",
              "      <td>0.766767</td>\n",
              "      <td>0.755860</td>\n",
              "      <td>0.014601</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.038642</td>\n",
              "      <td>0.002358</td>\n",
              "      <td>0.003186</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>entropy</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
              "      <td>0.734300</td>\n",
              "      <td>0.728865</td>\n",
              "      <td>0.713768</td>\n",
              "      <td>0.650151</td>\n",
              "      <td>0.725680</td>\n",
              "      <td>0.710553</td>\n",
              "      <td>0.030941</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.030989</td>\n",
              "      <td>0.001562</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>entropy</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
              "      <td>0.703502</td>\n",
              "      <td>0.710145</td>\n",
              "      <td>0.641304</td>\n",
              "      <td>0.752266</td>\n",
              "      <td>0.711782</td>\n",
              "      <td>0.703800</td>\n",
              "      <td>0.035661</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.025350</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.003093</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>entropy</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
              "      <td>0.743357</td>\n",
              "      <td>0.702899</td>\n",
              "      <td>0.677536</td>\n",
              "      <td>0.709366</td>\n",
              "      <td>0.675529</td>\n",
              "      <td>0.701737</td>\n",
              "      <td>0.024756</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.017561</td>\n",
              "      <td>0.000745</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>gini</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 3, 'max_fea...</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.707126</td>\n",
              "      <td>0.660628</td>\n",
              "      <td>0.640483</td>\n",
              "      <td>0.753474</td>\n",
              "      <td>0.691473</td>\n",
              "      <td>0.039136</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.020766</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.003282</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>entropy</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 3, 'max_...</td>\n",
              "      <td>0.672705</td>\n",
              "      <td>0.711957</td>\n",
              "      <td>0.743357</td>\n",
              "      <td>0.613293</td>\n",
              "      <td>0.629003</td>\n",
              "      <td>0.674063</td>\n",
              "      <td>0.048914</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows \u00d7 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "14       0.133932      0.001346  ...        0.014250                1\n",
              "13       0.077481      0.000836  ...        0.015491                2\n",
              "54       0.246913      0.004190  ...        0.016027                3\n",
              "9        0.077568      0.000340  ...        0.015663                4\n",
              "50       0.048760      0.000671  ...        0.014601                5\n",
              "..            ...           ...  ...             ...              ...\n",
              "46       0.038642      0.002358  ...        0.030941               76\n",
              "42       0.030989      0.001562  ...        0.035661               77\n",
              "41       0.025350      0.000200  ...        0.024756               78\n",
              "1        0.017561      0.000745  ...        0.039136               79\n",
              "40       0.020766      0.000195  ...        0.048914               80\n",
              "\n",
              "[80 rows x 16 columns]"
            ]
          },
          "execution_count": 93,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Applying GridSearchCV to find optimal hyperparameters to improve our classification report.\n",
        "# We are looking at a few parameters to see what works best with our model.\n",
        "tree_para = {'criterion':['gini','entropy'],\n",
        "             'max_depth':[3,5,10,25,50,100,200,500],\n",
        "             'max_features':[3,4,5,10,18]}\n",
        "clf = GridSearchCV(decision_tree, tree_para, cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Putting our results into a Pandas DataFrame for easier interpretation.\n",
        "gscv_df = pd.DataFrame(clf.cv_results_)\n",
        "gscv_df.sort_values('rank_test_score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V-VW6lyf54O"
      },
      "source": [
        "Our parameter grid search results from GridSearchCV have been put into a Pandas DataFrame for easier interpretation and ordered by test rank score. We will select the parameters with the highest test scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MiqBF1gAn4N",
        "outputId": "b3200649-ba7d-48a8-8411-ef92d103ec57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.178 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize and train our tree using parameters from GridSearchCV.\n",
        "decision_tree = tree.DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth=10,\n",
        "    max_features=18,\n",
        ")\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LLsdJt2gVdl"
      },
      "source": [
        "Interestingly our runtime was actually increased compared to our decision tree model before feature selection. This could be due to increased data complexity with PCA which decomposes new features instead of selecting the best features based on k value like selectkbest does. The hyperparameters involved for best performance here may cause increased runtime as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbHMUNo-A_eo",
        "outputId": "6c48c223-2b2d-48f8-d433-0ab792b3ead7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report:\n",
            "Accuracy:  0.7942028985507247\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.84      0.72      0.78      1021\n",
            "         Yes       0.76      0.86      0.81      1049\n",
            "\n",
            "    accuracy                           0.79      2070\n",
            "   macro avg       0.80      0.79      0.79      2070\n",
            "weighted avg       0.80      0.79      0.79      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[739 282]\n",
            " [144 905]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = decision_tree.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test,y_pred)\n",
        "decision_tree_report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(\"Accuracy: \", dt_accuracy)\n",
        "print(decision_tree_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jcsmdhZGfsZ"
      },
      "source": [
        "Our model is not performing as well as it did with selectkbest or before feature selection. PCA is not optimal for the decision tree classification task in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnPHHO3YGQNp"
      },
      "source": [
        "# Random Forest using PCA + GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4Tq27apAEj7f"
      },
      "outputs": [],
      "source": [
        "# Creating a Random Forest Classifier to use with GridSearchCV.\n",
        "rfc = ensemble.RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kBm9kzj0hJt8"
      },
      "outputs": [],
      "source": [
        "# Creating a parameter grid to find best combination of hyperparameters. \n",
        "param_grid = { \n",
        "    'n_estimators': [200, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [5,8,10,15,18],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49QOgHt4hOQ3",
        "outputId": "ba779a2f-33fb-4ffb-9b86-fdb2078bbb13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [5, 8, 10, 15, 18],\n",
              "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'n_estimators': [200, 500]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Using GridSearchCV to find best hyperparamater combination.\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "\n",
        "# Fitting GridSearchCV to our newly decomposed data.\n",
        "CV_rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhFAdAGbhdTb",
        "outputId": "bfe50761-0358-4eda-e4a9-955f461a8893"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 15,\n",
              " 'max_features': 'auto',\n",
              " 'n_estimators': 500}"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling best_params_ to find best parameters from GridSearchCV.\n",
        "CV_rfc.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvaRmkN_EVNb",
        "outputId": "8866adee-1779-42d7-ffe3-15a3ba20778d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 8.035 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# Timing our model.\n",
        "start_time = time.time()\n",
        "\n",
        "# Creating our model using optimized hyperparameters from GridSearchCV.\n",
        "rfc = ensemble.RandomForestClassifier(criterion='entropy', \n",
        "                                      max_depth=8,\n",
        "                                      max_features='auto',\n",
        "                                      n_estimators=200, random_state=42)\n",
        "\n",
        "# Fit our newly decomposed data to our model.\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Print model time. \n",
        "print(\"--- %s seconds ---\" % round(time.time() - start_time, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nJh0_ndmhgD"
      },
      "source": [
        "Model runtime was dramatically increased compared to our initial model without feature decomposition and our model that used selectkbest selected features. This may be due to the increased feature size of our PCA data need to achieve features that explained 95% of our targets variance compared to selectkbest. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW85mABiLPgR",
        "outputId": "3a522b1e-0d45-453e-ddf5-0ee223249020"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.79830918, 0.80676329, 0.76086957, 0.75603865, 0.77415459,\n",
              "       0.80193237, 0.81763285, 0.78985507, 0.77267231, 0.81136638])"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print cross-validation score.\n",
        "cross_val_score(rfc, X_train, y_train, cv=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8z5MnLwGxs5",
        "outputId": "cb3c6c74-2e6c-4df8-e85c-5dc6cd7ab147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report:\n",
            "Accuracy:  0.8057971014492754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       0.83      0.76      0.79      1021\n",
            "         Yes       0.78      0.85      0.82      1049\n",
            "\n",
            "    accuracy                           0.81      2070\n",
            "   macro avg       0.81      0.81      0.81      2070\n",
            "weighted avg       0.81      0.81      0.81      2070\n",
            "\n",
            "Confusion matrix:\n",
            "[[775 246]\n",
            " [156 893]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = rfc.predict(X_test) \n",
        "rfc_accuracy = accuracy_score(y_test,y_pred)\n",
        "rfc_report = classification_report(y_test, y_pred)\n",
        "rfc_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(\"Accuracy: \", rfc_accuracy)\n",
        "print(rfc_report)\n",
        "print(\"Confusion matrix:\")\n",
        "print(rfc_cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul0YBHjiIxPa"
      },
      "source": [
        "Metrics for our classification report were also not improved after feature decomposition with PCA and performance was reduced in comparison to the smaller selectkbest feature set. One would expect PCA to outperform as it had a higher dimensional set of features but it did not indicating some features were not useful but still were integrated into the PCA data. This indicates our random forest model performs best on this dataset without feature selection or decomposition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnEJq16IG94x"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UPA5YVeqn-z"
      },
      "source": [
        "  In conclusion, we were able to obtain repeatable results using a wide variety of models. Some models were much better suited to this dataset than others in regards to runtime and classification report metrics. Our random forest model without any feature selection or decomposition was our best performing model and able to run moderately fast in comparison to some other models with less accuracy such as SVM. Gradient boosting was able to obtain the same results at double the runtime with even longer runtimes when combined with other feature selection and decomposition techniques. Cross-validation variance was also minimal in comparison to our other models and none of the models tested display signs of overfitting or underfitting. \n",
        "\n",
        "Using feature selection with SelectKBest we were able to significantly reduce our run time in our random forest model but at the cost of less accuracy (5%). Since our run time is not that long anyways it seems our random forest model without any feature selection is going to be our best model to predict potential customer churn with a model accuracy of 86.8% and runtime of about 1 second. Inversely, PCA increased run time with random forest to 8 seconds while impacting performance. This demonstrates that feature selection and decomposition methods do not always give the best result depending on the desired model, so it is important to thoroughly test various implementations in order to find the best fit. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Senior Analysis: Production Churn Prevention System\n",
        "\n",
        "The exploratory work above maps the churn landscape. Below we build a\n",
        "**production-grade churn prediction system** with the rigor expected in a\n",
        "telecom data science team:\n",
        "\n",
        "| Practice | Business impact |\n",
        "|---|---|\n",
        "| **Pipeline** | Eliminates data leakage; model can be serialized and deployed as-is |\n",
        "| **Stratified CV** | Ensures each fold reflects the ~27% churn rate |\n",
        "| **Multi-metric** | Recall matters most \u2014 every missed churner costs $500+ in acquisition |\n",
        "| **SHAP** | Retention team needs actionable reasons, not just a score |\n",
        "| **Cost-sensitive analysis** | Quantifies the dollar impact of model decisions |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Senior Analysis: Pipeline + Multi-Metric CV + SHAP ---\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import (\n",
        "    cross_validate, StratifiedKFold, train_test_split\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score,\n",
        "    ConfusionMatrixDisplay, RocCurveDisplay, precision_recall_curve\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import xgboost as xgb_senior\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from portfolio_utils.data_loader import load_telecom_churn\n",
        "    df_s = load_telecom_churn()\n",
        "except Exception:\n",
        "    df_s = df.copy()\n",
        "\n",
        "# Preprocessing: encode categoricals, drop IDs/text\n",
        "drop_cols = [c for c in ['customerID', 'CustomerID', 'TotalCharges', 'Total Charges',\n",
        "             'Churn Label', 'Churn Value', 'Churn Score', 'CLTV',\n",
        "             'Churn Reason', 'Count', 'Country', 'State', 'City',\n",
        "             'Zip Code', 'Lat Long', 'Latitude', 'Longitude'] if c in df_s.columns]\n",
        "y_s = df_s['Churn'].map({'Yes': 1, 'No': 0}) if df_s['Churn'].dtype == 'object' else df_s['Churn']\n",
        "X_raw = df_s.drop(columns=['Churn'] + drop_cols, errors='ignore')\n",
        "X_s = pd.get_dummies(X_raw, drop_first=True).astype(float)\n",
        "\n",
        "print(f'Features: {X_s.shape[1]}, Samples: {X_s.shape[0]}')\n",
        "print(f'Churn rate: {y_s.mean():.1%}')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
        "    X_s, y_s, test_size=0.2, stratify=y_s, random_state=42\n",
        ")\n",
        "\n",
        "models = {\n",
        "    'XGBoost': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', xgb_senior.XGBClassifier(random_state=42, eval_metric='logloss',\n",
        "                                         scale_pos_weight=len(y_s[y_s==0])/len(y_s[y_s==1]))),\n",
        "    ]),\n",
        "    'Random Forest': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)),\n",
        "    ]),\n",
        "    'Gradient Boosting': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', GradientBoostingClassifier(random_state=42)),\n",
        "    ]),\n",
        "    'Logistic Regression': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "scoring = {'accuracy': 'accuracy', 'precision': 'precision', 'recall': 'recall',\n",
        "           'f1': 'f1', 'roc_auc': 'roc_auc'}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "results = {}\n",
        "for name, pipe in models.items():\n",
        "    cv_res = cross_validate(pipe, X_train_s, y_train_s, cv=cv,\n",
        "                            scoring=scoring, n_jobs=-1)\n",
        "    results[name] = {m: cv_res[f'test_{m}'].mean() for m in scoring}\n",
        "    print(f'{name}: Recall={results[name][\"recall\"]:.4f}, F1={results[name][\"f1\"]:.4f}, '\n",
        "          f'ROC-AUC={results[name][\"roc_auc\"]:.4f}')\n",
        "\n",
        "results_df = pd.DataFrame(results).T.round(4)\n",
        "results_df\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "results_df.plot.bar(ax=ax, rot=0)\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Churn Model Comparison: 5-Fold Stratified CV')\n",
        "ax.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Holdout evaluation with best model (by recall \u2014 catching churners is priority)\n",
        "best_name = results_df['recall'].idxmax()\n",
        "best_pipe = models[best_name]\n",
        "best_pipe.fit(X_train_s, y_train_s)\n",
        "\n",
        "y_pred_s = best_pipe.predict(X_test_s)\n",
        "y_proba_s = best_pipe.predict_proba(X_test_s)[:, 1]\n",
        "\n",
        "print(f'Best model (by recall): {best_name}')\n",
        "print()\n",
        "print(classification_report(y_test_s, y_pred_s, target_names=['Stayed', 'Churned']))\n",
        "print(f'ROC-AUC: {roc_auc_score(y_test_s, y_proba_s):.4f}')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test_s, y_pred_s, display_labels=['Stayed', 'Churned'],\n",
        "    cmap='Blues', ax=ax1\n",
        ")\n",
        "ax1.set_title('Confusion Matrix')\n",
        "RocCurveDisplay.from_predictions(y_test_s, y_proba_s, ax=ax2, name=best_name)\n",
        "ax2.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
        "ax2.set_title('ROC Curve')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cost-sensitive analysis\n",
        "\n",
        "In telecom, acquiring a new customer costs **$500\u2013$700** while a targeted retention\n",
        "offer costs **$50\u2013$100**. Every false negative (missed churner) is a $500+ loss;\n",
        "every false positive (unnecessary offer) costs ~$75. This asymmetry should drive\n",
        "threshold selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cost-sensitive threshold analysis\n",
        "cost_fn = 500   # cost of missing a churner (acquisition cost)\n",
        "cost_fp = 75    # cost of unnecessary retention offer\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test_s, y_proba_s)\n",
        "\n",
        "n_churners = y_test_s.sum()\n",
        "n_stayed = len(y_test_s) - n_churners\n",
        "\n",
        "costs = []\n",
        "for t in thresholds:\n",
        "    y_t = (y_proba_s >= t).astype(int)\n",
        "    fn = ((y_test_s == 1) & (y_t == 0)).sum()\n",
        "    fp = ((y_test_s == 0) & (y_t == 1)).sum()\n",
        "    total_cost = fn * cost_fn + fp * cost_fp\n",
        "    costs.append({'threshold': t, 'FN': fn, 'FP': fp,\n",
        "                  'missed_churner_cost': fn * cost_fn,\n",
        "                  'wasted_offer_cost': fp * cost_fp,\n",
        "                  'total_cost': total_cost})\n",
        "\n",
        "cost_df = pd.DataFrame(costs)\n",
        "optimal_idx = cost_df['total_cost'].idxmin()\n",
        "optimal = cost_df.iloc[optimal_idx]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.plot(cost_df['threshold'], cost_df['total_cost'], linewidth=2)\n",
        "ax.axvline(x=optimal['threshold'], color='red', linestyle='--',\n",
        "           label=f'Optimal: {optimal[\"threshold\"]:.2f} (${optimal[\"total_cost\"]:,.0f})')\n",
        "ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5, label='Default 0.5')\n",
        "ax.set_xlabel('Classification Threshold')\n",
        "ax.set_ylabel('Total Cost ($)')\n",
        "ax.set_title('Cost-Sensitive Threshold Optimization')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Optimal threshold: {optimal[\"threshold\"]:.3f}')\n",
        "print(f'  Missed churners: {optimal[\"FN\"]:.0f} (${optimal[\"missed_churner_cost\"]:,.0f})')\n",
        "print(f'  Unnecessary offers: {optimal[\"FP\"]:.0f} (${optimal[\"wasted_offer_cost\"]:,.0f})')\n",
        "print(f'  Total cost: ${optimal[\"total_cost\"]:,.0f}')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP interpretability\n",
        "\n",
        "The retention team needs to know **why** a customer is likely to churn so they can\n",
        "craft targeted interventions (e.g., contract renegotiation, service upgrade, billing\n",
        "adjustment). SHAP provides per-feature explanations for every prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    import shap\n",
        "    estimator = best_pipe.named_steps['clf']\n",
        "    preprocessor = Pipeline(best_pipe.steps[:-1])\n",
        "    X_train_t = preprocessor.transform(X_train_s)\n",
        "    feature_names = X_s.columns.tolist()\n",
        "\n",
        "    sample = X_train_t[:300]\n",
        "    explainer = shap.TreeExplainer(estimator, sample)\n",
        "    shap_values = explainer.shap_values(sample)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    shap.summary_plot(shap_values, sample, feature_names=feature_names,\n",
        "                      max_display=15, show=False)\n",
        "    plt.title('SHAP: What Drives Customer Churn?')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except ImportError:\n",
        "    print('Install shap: pip install shap')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business recommendations\n",
        "\n",
        "**For the VP of Customer Retention:**\n",
        "\n",
        "1. **Deploy the churn model** as a daily batch scoring job. Flag customers with\n",
        "   churn probability above the cost-optimized threshold for proactive outreach.\n",
        "\n",
        "2. **Use SHAP-driven interventions.** If a customer's top churn driver is\n",
        "   `MonthlyCharges`, offer a discount. If it's `Contract_Month-to-month`, offer\n",
        "   an annual contract incentive. Generic retention offers waste budget.\n",
        "\n",
        "3. **Prioritize recall over precision.** At $500 per lost customer vs. $75 per\n",
        "   unnecessary offer, it's 6.7\u00d7 more expensive to miss a churner than to\n",
        "   over-intervene. The cost-optimized threshold above reflects this.\n",
        "\n",
        "4. **Segment high-value churners.** Combine churn probability with customer\n",
        "   lifetime value (CLTV) to prioritize outreach \u2014 a high-CLTV churner deserves\n",
        "   a premium retention offer.\n",
        "\n",
        "5. **A/B test interventions.** Use the model to create treatment/control groups\n",
        "   and measure the causal impact of retention offers on actual churn rates.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AvZ5XaDJIWzg",
        "zs275zB7uEOf",
        "WtDVBYQkpzDD",
        "bJOpe607uWCa",
        "7EBJrmXWnNTs",
        "Wa3z5Ac8XzLO",
        "rdvxYkuoZE3j",
        "VYB1UOsBUT09",
        "BBd5wGo1hIyq",
        "_3eU4hPJGPg_",
        "Xgf7OPBHse-g",
        "q_wNVn1XuQN6",
        "E3D63tSFu3hv",
        "ttFXYdW8c6GA",
        "XtknzVWL1gZA",
        "0zD9bSymkFgx",
        "SYY082d0zKTI",
        "gmfxVesj0J5D"
      ],
      "name": "Supervised Learning Capstone: Telecom Churn Dataset (IBM Watson Analytics).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}